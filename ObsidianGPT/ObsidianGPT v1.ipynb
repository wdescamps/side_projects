{
 "cells": [
  {
   "cell_type": "raw",
   "id": "942394d4",
   "metadata": {},
   "source": [
    "The goal of this notebook is to automate the creation of an Obsidian Vault, containing the most well known ML and deep learning models for each datatype.\n",
    "The graph view will then allow easy exploration of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f234c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9b4cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import datetime\n",
    "import requests\n",
    "import openai\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea324d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API key stored in local cfg file\n",
    "# How to is available here : https://towardsdatascience.com/keeping-credentials-safe-in-jupyter-notebooks-fbd215a8e311\n",
    "\n",
    "parser = ConfigParser()\n",
    "_ = parser.read('ObsidianGPT.cfg')\n",
    "openai.api_key = parser.get('my_api', 'auth_key')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e4314c3",
   "metadata": {},
   "source": [
    "#Show available OPENAI models\n",
    "for i in openai.Model.list()[\"data\"]:\n",
    "    print(i[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc36b2",
   "metadata": {},
   "source": [
    "# Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d576a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, GPTmodel):\n",
    "    response = openai.ChatCompletion.create(model=GPTmodel,messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b8f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_obsidian_vault(vault_name, parent_directory):\n",
    "    '''Creates or Updates and Obsidian vault, in a given directory. Params are vault_name, parent_directory'''\n",
    "    vault_path = os.path.join(parent_directory, vault_name)\n",
    "    \n",
    "    # Create the vault directory\n",
    "    os.makedirs(vault_path, exist_ok=True)\n",
    "\n",
    "    # Create default folders within the vault\n",
    "    os.makedirs(os.path.join(vault_path, \"attachments\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(vault_path, \"notes\"), exist_ok=True)\n",
    "    \n",
    "    return vault_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4db4f",
   "metadata": {},
   "source": [
    "# Create and/or modify a local obsidian vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4574a269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/WDescamps/Desktop/code_projects/side_projects/ObsidianGPT/MyNewVault'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vault_path = create_obsidian_vault(vault_name=\"MyNewVault\", parent_directory=os.getcwd())\n",
    "vault_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51859d3d",
   "metadata": {},
   "source": [
    "## Prompt created by GPT, asking him to create a prompt to match my input of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "045f43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of models for different kinds of data from the GPT API\n",
    "models_prompt = \"\"\"\n",
    "Provide a list of popular machine learning and deep learning models for different types of data, \n",
    "grouped by data type and problem type. Include Numerical Data with Regression and Classification models, \n",
    "Categorical Data with Classification models, Text Data with Natural Language Processing models, \n",
    "Image Data with Computer Vision models and Image Generation models, Time Series Data with Forecasting models, \n",
    "Audio Data with Speech Recognition and Music Generation models, Reinforcement Learning with Model-free \n",
    "and Model-based Algorithms, and Unstructured Data with Clustering and Dimensionality Reduction models.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f34eaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get the list of models, for each data type and problem type\n",
    "models_text = generate_text(models_prompt, GPTmodel=\"gpt-4\") #or gpt-3.5-turbo\n",
    "models_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a72694a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Numerical Data\\n   - Regression Models\\n     - Linear Regression\\n     - Lasso Regression\\n     - Ridge Regression\\n     - Elastic Net\\n     - Support Vector Regression (SVR)\\n     - Decision Tree Regression\\n     - Random Forest Regression\\n     - AdaBoost Regression\\n     - Gradient Boosting Regression\\n     - XGBoost\\n     - LightGBM\\n     - CatBoost\\n   \\n   - Classification Models\\n     - Logistic Regression\\n     - Support Vector Machines (SVM)\\n     - Decision Trees\\n     - Random Forests\\n     - Naive Bayes\\n     - k-Nearest Neighbors (k-NN)\\n     - AdaBoost\\n     - Gradient Boosting Machines (GBM)\\n     - XGBoost\\n     - LightGBM\\n     - CatBoost\\n\\n2. Categorical Data\\n   - Classification Models\\n     - Same as numerical classification models, as categorical data can be processed by encoding it into numerical representations.\\n     - Categorical Naive Bayes\\n     - Categorical Neural Networks (embedding layers)\\n\\n3. Text Data\\n   - Natural Language Processing Models\\n     - Bag of Words\\n     - TF-IDF\\n     - Word2Vec\\n     - GloVe\\n     - FastText\\n     - Recurrent Neural Networks (RNN)\\n     - Long Short-Term Memory (LSTM)\\n     - Gated Recurrent Units (GRU)\\n     - Transformers (e.g., BERT, GPT, T5, RoBERTa)\\n\\n4. Image Data\\n   - Computer Vision Models\\n     - Convolutional Neural Networks (CNN)\\n     - ResNet\\n     - Inception\\n     - VGG\\n     - MobileNet\\n     - DenseNet\\n     - EfficientNet\\n   \\n   - Image Generation Models\\n     - Variational Autoencoders (VAE)\\n     - Generative Adversarial Networks (GAN)\\n     - StyleGAN\\n     - Pix2Pix\\n     - CycleGAN\\n\\n5. Time Series Data\\n   - Forecasting Models\\n     - Autoregressive Integrated Moving Average (ARIMA)\\n     - Seasonal decomposition of time series (STL)\\n     - Exponential Smoothing State Space Models (ETS)\\n     - Recurrent Neural Networks (RNN)\\n     - Long Short-Term Memory (LSTM)\\n     - Gated Recurrent Units (GRU)\\n     - Facebook Prophet\\n     - LightGBM\\n     - XGBoost\\n\\n6. Audio Data\\n   - Speech Recognition Models\\n     - Mel Frequency Cepstral Coefficients (MFCC)\\n     - Hidden Markov Models (HMM)\\n     - DeepSpeech\\n     - Listen, Attend and Spell (LAS)\\n\\n   - Music Generation Models\\n     - WaveNet\\n     - MelodyRNN\\n     - MidiNet\\n     - Transformer models\\n\\n7. Reinforcement Learning\\n   - Model-free Algorithms\\n     - Q-Learning\\n     - Deep Q-Network (DQN)\\n     - SARSA\\n     - Deep Deterministic Policy Gradient (DDPG)\\n     - Proximal Policy Optimization (PPO)\\n     - Actor-Critic (A2C, A3C)\\n     - Soft Actor-Critic (SAC)\\n\\n   - Model-based Algorithms\\n     - Monte Carlo Tree Search (MCTS)\\n     - PILCO\\n     - World Models\\n\\n8. Unstructured Data\\n   - Clustering Models\\n     - K-means\\n     - DBSCAN\\n     - Hierarchical Clustering\\n     - Mean Shift\\n     - Gaussian Mixture Models (GMM)\\n   \\n   - Dimensionality Reduction Models\\n     - Principal Component Analysis (PCA)\\n     - Linear Discriminant Analysis (LDA)\\n     - t-distributed Stochastic Neighbor Embedding (t-SNE)\\n     - Uniform Manifold Approximation and Projection (UMAP)\\n     - Autoencoders'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba3bda",
   "metadata": {},
   "source": [
    "## Clean model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26f652bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': ' Linear Regression', 'model_type': ' Regression Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Lasso Regression', 'model_type': ' Regression Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Ridge Regression', 'model_type': ' Regression Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Elastic Net', 'model_type': ' Regression Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Support Vector Regression (SVR)', 'model_type': ' Regression Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Decision Tree Regression', 'model_type': ' Regression Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Random Forest Regression', 'model_type': ' Regression Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' AdaBoost Regression', 'model_type': ' Regression Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Gradient Boosting Regression', 'model_type': ' Regression Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' XGBoost', 'model_type': ' Regression Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' LightGBM', 'model_type': ' Regression Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' CatBoost', 'model_type': ' Regression Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Logistic Regression', 'model_type': ' Classification Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Support Vector Machines (SVM)', 'model_type': ' Classification Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Decision Trees', 'model_type': ' Classification Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Random Forests', 'model_type': ' Classification Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Naive Bayes', 'model_type': ' Classification Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' k', 'model_type': ' Classification Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' AdaBoost', 'model_type': ' Classification Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Gradient Boosting Machines (GBM)', 'model_type': ' Classification Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' XGBoost', 'model_type': ' Classification Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' LightGBM', 'model_type': ' Classification Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' CatBoost', 'model_type': ' Classification Models', 'data_type': ' Numerical Data'}\n",
      "{'name': ' Same as numerical classification models, as categorical data can be processed by encoding it into numerical representations.', 'model_type': ' Classification Models', 'data_type': ' Categorical Data'}\n",
      "{'name': ' Categorical Naive Bayes', 'model_type': ' Classification Models', 'data_type': ' Categorical Data'}\n",
      "{'name': ' Categorical Neural Networks (embedding layers)', 'model_type': ' Classification Models', 'data_type': ' Categorical Data'}\n",
      "{'name': ' Bag of Words', 'model_type': ' Natural Language Processing Models', 'data_type': ' Text Data'}\n",
      "{'name': ' TF', 'model_type': ' Natural Language Processing Models', 'data_type': ' Text Data'}\n",
      "{'name': ' Word2Vec', 'model_type': ' Natural Language Processing Models', 'data_type': ' Text Data'}\n",
      "{'name': ' GloVe', 'model_type': ' Natural Language Processing Models', 'data_type': ' Text Data'}\n",
      "{'name': ' FastText', 'model_type': ' Natural Language Processing Models', 'data_type': ' Text Data'}\n",
      "{'name': ' Recurrent Neural Networks (RNN)', 'model_type': ' Natural Language Processing Models', 'data_type': ' Text Data'}\n",
      "{'name': ' Long Short', 'model_type': ' Natural Language Processing Models', 'data_type': ' Text Data'}\n",
      "{'name': ' Gated Recurrent Units (GRU)', 'model_type': ' Natural Language Processing Models', 'data_type': ' Text Data'}\n",
      "{'name': ' Transformers (e.g., BERT, GPT, T5, RoBERTa)', 'model_type': ' Natural Language Processing Models', 'data_type': ' Text Data'}\n",
      "{'name': ' Convolutional Neural Networks (CNN)', 'model_type': ' Computer Vision Models', 'data_type': ' Image Data'}\n",
      "{'name': ' ResNet', 'model_type': ' Computer Vision Models', 'data_type': ' Image Data'}\n",
      "{'name': ' Inception', 'model_type': ' Computer Vision Models', 'data_type': ' Image Data'}\n",
      "{'name': ' VGG', 'model_type': ' Computer Vision Models', 'data_type': ' Image Data'}\n",
      "{'name': ' MobileNet', 'model_type': ' Computer Vision Models', 'data_type': ' Image Data'}\n",
      "{'name': ' DenseNet', 'model_type': ' Computer Vision Models', 'data_type': ' Image Data'}\n",
      "{'name': ' EfficientNet', 'model_type': ' Computer Vision Models', 'data_type': ' Image Data'}\n",
      "{'name': ' Variational Autoencoders (VAE)', 'model_type': ' Image Generation Models', 'data_type': ' Image Data'}\n",
      "{'name': ' Generative Adversarial Networks (GAN)', 'model_type': ' Image Generation Models', 'data_type': ' Image Data'}\n",
      "{'name': ' StyleGAN', 'model_type': ' Image Generation Models', 'data_type': ' Image Data'}\n",
      "{'name': ' Pix2Pix', 'model_type': ' Image Generation Models', 'data_type': ' Image Data'}\n",
      "{'name': ' CycleGAN', 'model_type': ' Image Generation Models', 'data_type': ' Image Data'}\n",
      "{'name': ' Autoregressive Integrated Moving Average (ARIMA)', 'model_type': ' Forecasting Models', 'data_type': ' Time Series Data'}\n",
      "{'name': ' Seasonal decomposition of time series (STL)', 'model_type': ' Forecasting Models', 'data_type': ' Time Series Data'}\n",
      "{'name': ' Recurrent Neural Networks (RNN)', 'model_type': ' Exponential Smoothing State Space Models (ETS)', 'data_type': ' Time Series Data'}\n",
      "{'name': ' Long Short', 'model_type': ' Exponential Smoothing State Space Models (ETS)', 'data_type': ' Time Series Data'}\n",
      "{'name': ' Gated Recurrent Units (GRU)', 'model_type': ' Exponential Smoothing State Space Models (ETS)', 'data_type': ' Time Series Data'}\n",
      "{'name': ' Facebook Prophet', 'model_type': ' Exponential Smoothing State Space Models (ETS)', 'data_type': ' Time Series Data'}\n",
      "{'name': ' LightGBM', 'model_type': ' Exponential Smoothing State Space Models (ETS)', 'data_type': ' Time Series Data'}\n",
      "{'name': ' XGBoost', 'model_type': ' Exponential Smoothing State Space Models (ETS)', 'data_type': ' Time Series Data'}\n",
      "{'name': ' Mel Frequency Cepstral Coefficients (MFCC)', 'model_type': ' Speech Recognition Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' DeepSpeech', 'model_type': ' Hidden Markov Models (HMM)', 'data_type': ' Audio Data'}\n",
      "{'name': ' Listen, Attend and Spell (LAS)', 'model_type': ' Hidden Markov Models (HMM)', 'data_type': ' Audio Data'}\n",
      "{'name': ' WaveNet', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' MelodyRNN', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' MidiNet', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' Transformer models', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' Model', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' Q', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' Deep Q', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' SARSA', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' Deep Deterministic Policy Gradient (DDPG)', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' Proximal Policy Optimization (PPO)', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' Actor', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' Soft Actor', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' Model', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' Monte Carlo Tree Search (MCTS)', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' PILCO', 'model_type': ' Music Generation Models', 'data_type': ' Audio Data'}\n",
      "{'name': ' K', 'model_type': ' Clustering Models', 'data_type': ' Unstructured Data'}\n",
      "{'name': ' DBSCAN', 'model_type': ' Clustering Models', 'data_type': ' Unstructured Data'}\n",
      "{'name': ' Hierarchical Clustering', 'model_type': ' Clustering Models', 'data_type': ' Unstructured Data'}\n",
      "{'name': ' Mean Shift', 'model_type': ' Clustering Models', 'data_type': ' Unstructured Data'}\n",
      "{'name': ' Principal Component Analysis (PCA)', 'model_type': ' Dimensionality Reduction Models', 'data_type': ' Unstructured Data'}\n",
      "{'name': ' Linear Discriminant Analysis (LDA)', 'model_type': ' Dimensionality Reduction Models', 'data_type': ' Unstructured Data'}\n",
      "{'name': ' t', 'model_type': ' Dimensionality Reduction Models', 'data_type': ' Unstructured Data'}\n",
      "{'name': ' Uniform Manifold Approximation and Projection (UMAP)', 'model_type': ' Dimensionality Reduction Models', 'data_type': ' Unstructured Data'}\n",
      "{'name': ' Autoencoders', 'model_type': ' Dimensionality Reduction Models', 'data_type': ' Unstructured Data'}\n"
     ]
    }
   ],
   "source": [
    "output = models_text\n",
    "\n",
    "lines = output.split(\"\\n\")\n",
    "models = []\n",
    "\n",
    "current_data_type = \"\"\n",
    "current_model_type = \"\"\n",
    "\n",
    "for line in lines:\n",
    "    if line == \"\":\n",
    "        continue\n",
    "    \n",
    "    if \"Data\" in line :\n",
    "        current_data_type = line.strip().split(\".\")[1]\n",
    "        continue\n",
    "    \n",
    "    if \"Models\" in line:\n",
    "        current_model_type = line.strip().split(\"-\")[1]\n",
    "        continue\n",
    "    \n",
    "    if \"-\" in line :\n",
    "        model_name = line.strip().split(\"-\")[1]\n",
    "        models.append({\"name\": model_name, \"model_type\": current_model_type, \"data_type\": current_data_type})\n",
    "\n",
    "# Print the parsed models\n",
    "for model in models:\n",
    "    print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8d0f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save models dict to disk with current date\n",
    "with open(f'models_{datetime.datetime.now().date()}.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69b82148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': ' Linear Regression',\n",
       "  'model_type': ' Regression Models',\n",
       "  'data_type': ' Numerical Data'},\n",
       " {'name': ' Lasso Regression',\n",
       "  'model_type': ' Regression Models',\n",
       "  'data_type': ' Numerical Data'},\n",
       " {'name': ' Ridge Regression',\n",
       "  'model_type': ' Regression Models',\n",
       "  'data_type': ' Numerical Data'},\n",
       " {'name': ' Elastic Net',\n",
       "  'model_type': ' Regression Models',\n",
       "  'data_type': ' Numerical Data'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7dbf9",
   "metadata": {},
   "source": [
    "## Add data to existing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ae118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(10000)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2479e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.23 s, sys: 391 ms, total: 2.63 s\n",
      "Wall time: 3h 5min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models_with_details=models\n",
    "for model in models_with_details:\n",
    "    resource_prompt = f\"\"\"\n",
    "    For the {model['name']} model, provide:\n",
    "    1. A brief description of the model.\n",
    "    2. The three most relevant use cases.\n",
    "    3. Three great resources with relevant internet links for implementing the model.\n",
    "    4. A python code which demonstrates the use of this model \n",
    "    \"\"\"\n",
    "    resources = generate_text(resource_prompt, GPTmodel=\"gpt-4\")\n",
    "    model[\"resources\"] = resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8fda87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save enriched models dict to disk with current date\n",
    "with open(f'models_with_details_{datetime.datetime.now().date()}.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(models_with_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7b83665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.38 ms, sys: 669 Âµs, total: 8.05 ms\n",
      "Wall time: 8.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for model in models_with_details:\n",
    "    output = model[\"resources\"]\n",
    "\n",
    "    parsed_output = {}\n",
    "    keys = [\"description\", \"use_cases\", \"resources\", \"python_code\"]\n",
    "\n",
    "    lines = output.split(\"\\n\")\n",
    "    current_key = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"1.\"):\n",
    "            current_key = keys[0]\n",
    "            parsed_output[current_key] = line.split(\"1. \")[1].strip()\n",
    "        elif line.startswith(\"2.\"):\n",
    "            current_key = keys[1]\n",
    "            parsed_output[current_key] = []\n",
    "        elif line.startswith(\"3.\"):\n",
    "            current_key = keys[2]\n",
    "            parsed_output[current_key] = []\n",
    "        elif line.startswith(\"4.\"):\n",
    "            current_key = keys[3]\n",
    "            parsed_output[current_key] = \"\"\n",
    "        else:\n",
    "            if current_key == keys[1] or current_key == keys[2]:\n",
    "                content = line.strip()\n",
    "                if content:\n",
    "                    parsed_output[current_key].append(content)\n",
    "            elif current_key == keys[3]:\n",
    "                parsed_output[current_key] +=  line + \"\\n\"\n",
    "\n",
    "    # Print the parsed output\n",
    "    for key, value in parsed_output.items():\n",
    "        model[key]=value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ad958c",
   "metadata": {},
   "source": [
    "## Write to Obsidian Vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bfefdb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the models list\n",
    "for model in models_with_details:\n",
    "    model_filename = f\"{model['name']}.md\"\n",
    "    model_filepath = os.path.join(vault_path, model_filename)\n",
    "    data_type = model['data_type']\n",
    "    model_name = model['name']\n",
    "\n",
    "    # Create the directory for the data type if it does not exist\n",
    "    data_type_path = os.path.join(vault_path, data_type)\n",
    "    if not os.path.exists(data_type_path):\n",
    "        os.makedirs(data_type_path)\n",
    "\n",
    "    # Create a file for the model and write its information\n",
    "    file_name = f\"{model_name}.md\"\n",
    "    file_path = os.path.join(data_type_path, file_name)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(f\"# {model_name}\\n\")\n",
    "        f.write(f\"**Model Type:** {model['model_type']}\\n\")\n",
    "        f.write(f\"**Data Type:** {model['data_type']}\\n\\n\")\n",
    "        \n",
    "        #f.write(f\"**Description**:\\n\\n{model['description']}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"**Python code **:\\n\\n{model['python_code']}\\n\\n\")\n",
    "\n",
    "        # Add \"See Also\" section with links to related models\n",
    "        f.write(f\"**See Also**:\\n\\n\")\n",
    "        for other_model in models:\n",
    "            if other_model['name'] != model['name'] and other_model['data_type'] == model['data_type']:\n",
    "                f.write(f\"- [[{other_model['name']}]]\\n\")\n",
    "\n",
    "        # Add additional information about the model if available\n",
    "        if 'resources' in model:\n",
    "            f.write(\"## Resources\\n\\n\")\n",
    "            for resource in model['resources']:\n",
    "                f.write(resource +\"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        # Add relevant tags with hierarchy, strip special chars for clarity\n",
    "        f.write(f\"\\n---\\n\")\n",
    "        root_tag = model['data_type'].replace(' ', '-').lower()\n",
    "        leaf_tag = model['name'].replace('(', '').replace(')', '').replace(' ', '-').lower()\n",
    "        f.write(f\"tags: #{root_tag}, #{root_tag}/{leaf_tag}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414629cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

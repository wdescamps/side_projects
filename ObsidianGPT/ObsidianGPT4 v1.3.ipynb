{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a906aeb6",
   "metadata": {},
   "source": [
    "The goal of this notebook is to automate the creation of an Obsidian Vault, containing the most well known ML and deep learning models for each datatype.\n",
    "The graph view will then allow easy exploration of the models."
   ]
  },
  {
   "cell_type": "raw",
   "id": "810d627f",
   "metadata": {},
   "source": [
    "Next steps : \n",
    "    --> Also run the GPT4 query for the \"see also\" models\n",
    "    --> Try other queries for other domains, ie: cognitive neuroscience for example\n",
    "    --> Add metrics for each model (https://towardsdatascience.com/how-to-compare-machine-learning-algorithms-ccc266c4777)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f234c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b4cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import requests\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea324d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API key stored in local cfg file\n",
    "# How to is available here : https://towardsdatascience.com/keeping-credentials-safe-in-jupyter-notebooks-fbd215a8e311\n",
    "\n",
    "parser = ConfigParser()\n",
    "_ = parser.read('ObsidianGPT.cfg')\n",
    "openai.api_key = parser.get('my_api', 'auth_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03eba74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davinci\n",
      "gpt-3.5-turbo-16k-0613\n",
      "text-davinci-001\n",
      "text-search-curie-query-001\n",
      "babbage\n",
      "text-babbage-001\n",
      "gpt-3.5-turbo-16k\n",
      "curie-instruct-beta\n",
      "gpt-4-0314\n",
      "gpt-4\n",
      "davinci-similarity\n",
      "code-davinci-edit-001\n",
      "text-similarity-curie-001\n",
      "ada-code-search-text\n",
      "gpt-3.5-turbo-0613\n",
      "text-search-ada-query-001\n",
      "babbage-search-query\n",
      "ada-similarity\n",
      "text-curie-001\n",
      "text-search-ada-doc-001\n",
      "text-search-babbage-query-001\n",
      "code-search-ada-code-001\n",
      "curie-search-document\n",
      "davinci-002\n",
      "text-search-davinci-query-001\n",
      "text-search-curie-doc-001\n",
      "babbage-search-document\n",
      "babbage-002\n",
      "babbage-code-search-text\n",
      "text-embedding-ada-002\n",
      "davinci-instruct-beta\n",
      "davinci-search-query\n",
      "text-similarity-babbage-001\n",
      "text-davinci-002\n",
      "code-search-babbage-text-001\n",
      "text-davinci-003\n",
      "text-search-davinci-doc-001\n",
      "code-search-ada-text-001\n",
      "gpt-4-0613\n",
      "ada-search-query\n",
      "text-similarity-ada-001\n",
      "ada-code-search-code\n",
      "whisper-1\n",
      "text-davinci-edit-001\n",
      "davinci-search-document\n",
      "curie-search-query\n",
      "babbage-similarity\n",
      "ada\n",
      "ada-search-document\n",
      "text-ada-001\n",
      "text-similarity-davinci-001\n",
      "gpt-3.5-turbo\n",
      "curie-similarity\n",
      "babbage-code-search-code\n",
      "code-search-babbage-code-001\n",
      "text-search-babbage-doc-001\n",
      "gpt-3.5-turbo-0301\n",
      "curie\n"
     ]
    }
   ],
   "source": [
    "#Uncomment to show available OPENAI models\n",
    "for i in openai.Model.list()[\"data\"]:\n",
    "    print(i[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc36b2",
   "metadata": {},
   "source": [
    "# Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d576a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passes a specific prompt to the chosen OpenAI GPT model\n",
    "def generate_text(prompt, GPTmodel):\n",
    "    response = openai.ChatCompletion.create(model=GPTmodel,messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b8f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a local obsidian vault\n",
    "def create_obsidian_vault(vault_name, parent_directory):\n",
    "    '''Creates or Updates and Obsidian vault, in a given directory. Params are vault_name, parent_directory'''\n",
    "    vault_path = os.path.join(parent_directory, vault_name)\n",
    "    \n",
    "    # Create the vault directory\n",
    "    os.makedirs(vault_path, exist_ok=True)\n",
    "\n",
    "    # Create default folders within the vault\n",
    "    os.makedirs(os.path.join(vault_path, \"attachments\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(vault_path, \"notes\"), exist_ok=True)\n",
    "    \n",
    "    return vault_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe2f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract strings with regexp\n",
    "def regex_string_finder(input_string, pattern):\n",
    "    '''\n",
    "    Usage: regex_string_finder(\"This is a sample.text:with:colons\", r'\\.(.*?)\\:')\n",
    "    '''\n",
    "    # Use re.search to find the first match of the pattern\n",
    "    match = re.search(pattern, input_string)\n",
    "\n",
    "    # Check if a match is found\n",
    "    if match:\n",
    "        # Extract the substring between '.' and ':'\n",
    "        extracted_string = match.group(1)\n",
    "        return extracted_string.strip()\n",
    "    else:\n",
    "        return \"No match found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe3c070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_variable_to_text_file(variable, file_path):\n",
    "    # Open the file in write mode ('w')\n",
    "    with open(file_path, 'w') as file:\n",
    "        # Write the variable's value to the file\n",
    "        file.write(variable)\n",
    "    \n",
    "    print(f\"Variable written to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4db4f",
   "metadata": {},
   "source": [
    "# Create and/or modify the local Obsidian Vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4574a269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/WDescamps/Desktop/code_projects/side_projects/ObsidianGPT/MyNewVault-2023-09-07'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today=datetime.datetime.now()\n",
    "vault_path = create_obsidian_vault(vault_name=f\"MyNewVault\"+ \"-\" + str(today.date()), parent_directory=os.getcwd())\n",
    "vault_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51859d3d",
   "metadata": {},
   "source": [
    "## Prompt created by GPT, asking him to create a prompt to match my input of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5caaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quite a bit of trial and error prompting led to the following prompt. Feel free to experiment with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7e8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "045f43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of models for different kinds of data from the GPT API\n",
    "models_prompt = \"\"\"\n",
    "Provide an exhaustive list of popular machine learning and deep learning models for all types of data, \n",
    "grouped by data type and problem type.Provide as your response the dictionnary containing the results. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f34eaa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.9 ms, sys: 11.7 ms, total: 37.6 ms\n",
      "Wall time: 2min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"Structured Data\": {\\n    \"Regression\": [\\n      \"Linear Regression\",\\n      \"Ridge Regression\",\\n      \"Lasso Regression\",\\n      \"Elastic Net\",\\n      \"Support Vector Regression\",\\n      \"Decision Tree Regression\",\\n      \"Random Forest Regression\",\\n      \"AdaBoost Regression\",\\n      \"Gradient Boosting Regression\",\\n      \"XGBoost\",\\n      \"LightGBM\",\\n      \"CatBoost\",\\n      \"Artificial Neural Networks\",\\n      \"Long Short-Term Memory\"\\n    ],\\n    \"Classification\": [\\n      \"Logistic Regression\",\\n      \"Linear Discriminant Analysis\",\\n      \"Quadratic Discriminant Analysis\",\\n      \"Support Vector Machines\",\\n      \"Decision Tree Classifier\",\\n      \"Random Forest Classifier\",\\n      \"AdaBoost Classifier\",\\n      \"Gradient Boosting Classifier\",\\n      \"XGBoost Classifier\",\\n      \"LightGBM Classifier\",\\n      \"CatBoost Classifier\",\\n      \"K-Nearest Neighbors\",\\n      \"Naive Bayes Classifier\",\\n      \"Artificial Neural Networks\"\\n    ],\\n    \"Clustering\": [\\n      \"K-Means Clustering\",\\n      \"DBSCAN\",\\n      \"Hierarchical Clustering\",\\n      \"Spectral Clustering\",\\n      \"Mean Shift\",\\n      \"Affinity Propagation\",\\n      \"OPTICS\",\\n      \"BIRCH\"\\n    ],\\n    \"Dimensionality Reduction\": [\\n      \"Principal Component Analysis\",\\n      \"Linear Discriminant Analysis\",\\n      \"t-Distributed Stochastic Neighbor Embedding\",\\n      \"Factor Analysis\",\\n      \"Independent Component Analysis\",\\n      \"Uniform Manifold Approximation and Projection\",\\n      \"Autoencoders\"\\n    ],\\n    \"Anomaly Detection\": [\\n      \"Isolation Forest\",\\n      \"LOF\",\\n      \"One-Class SVM\",\\n      \"Elliptic Envelope\",\\n      \"DBSCAN\",\\n      \"K-means\",\\n      \"Autoencoders\"\\n    ],\\n    \"Reinforcement Learning\": [\\n      \"Q-Learning\",\\n      \"SARSA\",\\n      \"Deep Q-Network\",\\n      \"Policy Gradient Methods\",\\n      \"REINFORCE\",\\n      \"Proximal Policy Optimization\",\\n      \"Soft Actor-Critic\",\\n      \"Monte Carlo Tree Search\"\\n    ]\\n  },\\n  \"Time Series Data\": {\\n    \"Forecasting\": [\\n      \"Autoregressive Integrated Moving Average\",\\n      \"Exponential Smoothing State Space Model\",\\n      \"Seasonal Decomposition of Time Series\",\\n      \"Prophet\",\\n      \"Theta Methods\",\\n      \"Recurrent Neural Networks\",\\n      \"Long Short-Term Memory\",\\n      \"Gated Recurrent Units\",\\n      \"Convolutional Neural Networks\",\\n      \"WaveNet\"\\n    ],\\n    \"Anomaly Detection\": [\\n      \"Seasonal-Trend Decomposition using Loess\",\\n      \"Bayesian Structural Time Series Models\",\\n      \"Autoregressive Integrated Moving Average\",\\n      \"Long Short-Term Memory\",\\n      \"Gated Recurrent Units\",\\n      \"Autoencoders\"\\n    ]\\n  },\\n  \"Text Data\": {\\n    \"Natural Language Processing\": [\\n      \"Bag-of-Words\",\\n      \"TF-IDF\",\\n      \"Word2Vec\",\\n      \"GloVe\",\\n      \"FastText\",\\n      \"ElMo\",\\n      \"BERT\",\\n      \"GPT\",\\n      \"GPT-2\",\\n      \"GPT-3\",\\n      \"RoBERTa\",\\n      \"XLNet\",\\n      \"ALBERT\",\\n      \"T5\",\\n      \"DistilBERT\",\\n      \"MobileBERT\",\\n      \"UniLM\",\\n      \"OpenAI Codex\",\\n      \"Recurrent Neural Networks\",\\n      \"Long Short-Term Memory\",\\n      \"Gated Recurrent Units\",\\n      \"Convolutional Neural Networks\",\\n      \"Transformer Models\",\\n      \"Attention Mechanisms\",\\n      \"Sequence-to-Sequence Models\"\\n    ],\\n    \"Sentiment Analysis\": [\\n      \"Naive Bayes\",\\n      \"Logistic Regression\",\\n      \"Support Vector Machines\",\\n      \"Random Forest\",\\n      \"XGBoost\",\\n      \"Recurrent Neural Networks\",\\n      \"Long Short-Term Memory\",\\n      \"Gated Recurrent Units\",\\n      \"Convolutional Neural Networks\",\\n      \"BERT\",\\n      \"GPT\"\\n    ],\\n    \"Topic Modeling\": [\\n      \"Latent Dirichlet Allocation\",\\n      \"Non-negative Matrix Factorization\",\\n      \"Latent Semantic Analysis\",\\n      \"Correlational Correspondence Analysis\"\\n    ]\\n  },\\n  \"Image Data\": {\\n    \"Image Classification\": [\\n      \"Convolutional Neural Networks\",\\n      \"ResNet\",\\n      \"Inception\",\\n      \"VGG\",\\n      \"MobileNet\",\\n      \"EfficientNet\",\\n      \"DenseNet\",\\n      \"Xception\",\\n      \"NASNet\"\\n    ],\\n    \"Image Segmentation\": [\\n      \"Fully Convolutional Networks\",\\n      \"U-Net\",\\n      \"Mask R-CNN\",\\n      \"DeepLab\",\\n      \"PSPNet\",\\n      \"HRNet\"\\n    ],\\n    \"Object Detection\": [\\n      \"R-CNN\",\\n      \"Fast R-CNN\",\\n      \"Faster R-CNN\",\\n      \"YOLO\",\\n      \"SSD\",\\n      \"RetinaNet\",\\n      \"CenterNet\",\\n      \"EfficientDet\"\\n    ],\\n    \"Image Captioning\": [\\n      \"Encoder-Decoder Architectures\",\\n      \"Attention Models\",\\n      \"Show and Tell\",\\n      \"Show, Attend and Tell\",\\n      \"Adaptive Attention\",\\n      \"Transformer Models\"\\n    ],\\n    \"Style Transfer\": [\\n      \"Neural Style Transfer\",\\n      \"CycleGAN\",\\n      \"StarGAN\",\\n      \"AdaIN\"\\n    ],\\n    \"Generative Models\": [\\n      \"Autoencoders\",\\n      \"Variational Autoencoders\",\\n      \"Generative Adversarial Networks\",\\n      \"DCGAN\",\\n      \"Wasserstein GAN\",\\n      \"CycleGAN\",\\n      \"StyleGAN\",\\n      \"BigGAN\"\\n    ]\\n  },\\n  \"Audio Data\": {\\n    \"Speech Recognition\": [\\n      \"Hidden Markov Models\",\\n      \"Gaussian Mixture Models\",\\n      \"Deep Neural Networks\",\\n      \"Connectionist Temporal Classification\",\\n      \"Recurrent Neural Networks\",\\n      \"Long Short-Term Memory\",\\n      \"Gated Recurrent Units\",\\n      \"Listen, Attend, and Spell\",\\n      \"WaveNet\",\\n      \"Tacotron\",\\n      \"Transformer Models\"\\n    ],\\n    \"Speaker Identification/Verification\": [\\n      \"Gaussian Mixture Models\",\\n      \"Support Vector Machines\",\\n      \"i-vectors\",\\n      \"Deep Speaker Embeddings\",\\n      \"Recurrent Neural Networks\",\\n      \"Long Short-Term Memory\",\\n      \"Gated Recurrent Units\"\\n    ],\\n    \"Audio Classification\": [\\n      \"Mel Spectrogram\",\\n      \"MFCC\",\\n      \"Convolutional Neural Networks\",\\n      \"Recurrent Neural Networks\",\\n      \"Long Short-Term Memory\",\\n      \"Gated Recurrent Units\",\\n      \"Attention Models\",\\n      \"WaveNet\",\\n      \"Spectrogram\"\\n    ],\\n    \"Music Generation\": [\\n      \"Markov Models\",\\n      \"Restricted Boltzmann Machines\",\\n      \"Recurrent Neural Networks\",\\n      \"Long Short-Term Memory\",\\n      \"Gated Recurrent Units\",\\n      \"WaveNet\",\\n      \"Transformer Models\"\\n    ],\\n    \"Music Recommendation\": [\\n      \"Collaborative Filtering\",\\n      \"Matrix Factorization\",\\n      \"Autoencoders\",\\n      \"Restricted Boltzmann Machines\",\\n      \"Deep Neural Networks\",\\n      \"Recurrent Neural Networks\",\\n      \"Long Short-Term Memory\",\\n      \"Gated Recurrent Units\"\\n    ]\\n  },\\n  \"Graph Data\": {\\n    \"Graph Networks\": [\\n      \"Graph Convolutional Networks\",\\n      \"GraphSAGE\",\\n      \"Graph Attention Networks\",\\n      \"Graph Isomorphism Networks\",\\n      \"ChebNet\",\\n      \"GINConv\",\\n      \"Graph Neural Networks\",\\n      \"Dynamic Graph Representation Learning\"\\n    ],\\n    \"Graph Clustering\": [\\n      \"Spectral Clustering\",\\n      \"Graph Modularity Maximization\",\\n      \"Louvain Algorithm\",\\n      \"Infomap\",\\n      \"Label Propagation Algorithm\"\\n    ],\\n    \"Graph Embeddings\": [\\n      \"DeepWalk\",\\n      \"Node2Vec\",\\n      \"Graph Convolutional Network\",\\n      \"Structural Deep Network Embeddings\",\\n      \"GE-SNMF\"\\n    ]\\n  }\\n}'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Get the list of models, for each data type and problem type\n",
    "models_text = generate_text(models_prompt, GPTmodel=\"gpt-4-0314\") #Points to the latest GPT4 model or gpt-3.5-turbo for faster results vs lower query quality\n",
    "models_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bc69c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"structured data\": {\n",
      "    \"regression\": [\n",
      "      \"linear regression\",\n",
      "      \"ridge regression\",\n",
      "      \"lasso regression\",\n",
      "      \"elastic net\",\n",
      "      \"support vector regression\",\n",
      "      \"decision tree regression\",\n",
      "      \"random forest regression\",\n",
      "      \"adaboost regression\",\n",
      "      \"gradient boosting regression\",\n",
      "      \"xgboost\",\n",
      "      \"lightgbm\",\n",
      "      \"catboost\",\n",
      "      \"artificial neural networks\",\n",
      "      \"long short-term memory\"\n",
      "    ],\n",
      "    \"classification\": [\n",
      "      \"logistic regression\",\n",
      "      \"linear discriminant analysis\",\n",
      "      \"quadratic discriminant analysis\",\n",
      "      \"support vector machines\",\n",
      "      \"decision tree classifier\",\n",
      "      \"random forest classifier\",\n",
      "      \"adaboost classifier\",\n",
      "      \"gradient boosting classifier\",\n",
      "      \"xgboost classifier\",\n",
      "      \"lightgbm classifier\",\n",
      "      \"catboost classifier\",\n",
      "      \"k-nearest neighbors\",\n",
      "      \"naive bayes classifier\",\n",
      "      \"artificial neural networks\"\n",
      "    ],\n",
      "    \"clustering\": [\n",
      "      \"k-means clustering\",\n",
      "      \"dbscan\",\n",
      "      \"hierarchical clustering\",\n",
      "      \"spectral clustering\",\n",
      "      \"mean shift\",\n",
      "      \"affinity propagation\",\n",
      "      \"optics\",\n",
      "      \"birch\"\n",
      "    ],\n",
      "    \"dimensionality reduction\": [\n",
      "      \"principal component analysis\",\n",
      "      \"linear discriminant analysis\",\n",
      "      \"t-distributed stochastic neighbor embedding\",\n",
      "      \"factor analysis\",\n",
      "      \"independent component analysis\",\n",
      "      \"uniform manifold approximation and projection\",\n",
      "      \"autoencoders\"\n",
      "    ],\n",
      "    \"anomaly detection\": [\n",
      "      \"isolation forest\",\n",
      "      \"lof\",\n",
      "      \"one-class svm\",\n",
      "      \"elliptic envelope\",\n",
      "      \"dbscan\",\n",
      "      \"k-means\",\n",
      "      \"autoencoders\"\n",
      "    ],\n",
      "    \"reinforcement learning\": [\n",
      "      \"q-learning\",\n",
      "      \"sarsa\",\n",
      "      \"deep q-network\",\n",
      "      \"policy gradient methods\",\n",
      "      \"reinforce\",\n",
      "      \"proximal policy optimization\",\n",
      "      \"soft actor-critic\",\n",
      "      \"monte carlo tree search\"\n",
      "    ]\n",
      "  },\n",
      "  \"time series data\": {\n",
      "    \"forecasting\": [\n",
      "      \"autoregressive integrated moving average\",\n",
      "      \"exponential smoothing state space model\",\n",
      "      \"seasonal decomposition of time series\",\n",
      "      \"prophet\",\n",
      "      \"theta methods\",\n",
      "      \"recurrent neural networks\",\n",
      "      \"long short-term memory\",\n",
      "      \"gated recurrent units\",\n",
      "      \"convolutional neural networks\",\n",
      "      \"wavenet\"\n",
      "    ],\n",
      "    \"anomaly detection\": [\n",
      "      \"seasonal-trend decomposition using loess\",\n",
      "      \"bayesian structural time series models\",\n",
      "      \"autoregressive integrated moving average\",\n",
      "      \"long short-term memory\",\n",
      "      \"gated recurrent units\",\n",
      "      \"autoencoders\"\n",
      "    ]\n",
      "  },\n",
      "  \"text data\": {\n",
      "    \"natural language processing\": [\n",
      "      \"bag-of-words\",\n",
      "      \"tf-idf\",\n",
      "      \"word2vec\",\n",
      "      \"glove\",\n",
      "      \"fasttext\",\n",
      "      \"elmo\",\n",
      "      \"bert\",\n",
      "      \"gpt\",\n",
      "      \"gpt-2\",\n",
      "      \"gpt-3\",\n",
      "      \"roberta\",\n",
      "      \"xlnet\",\n",
      "      \"albert\",\n",
      "      \"t5\",\n",
      "      \"distilbert\",\n",
      "      \"mobilebert\",\n",
      "      \"unilm\",\n",
      "      \"openai codex\",\n",
      "      \"recurrent neural networks\",\n",
      "      \"long short-term memory\",\n",
      "      \"gated recurrent units\",\n",
      "      \"convolutional neural networks\",\n",
      "      \"transformer models\",\n",
      "      \"attention mechanisms\",\n",
      "      \"sequence-to-sequence models\"\n",
      "    ],\n",
      "    \"sentiment analysis\": [\n",
      "      \"naive bayes\",\n",
      "      \"logistic regression\",\n",
      "      \"support vector machines\",\n",
      "      \"random forest\",\n",
      "      \"xgboost\",\n",
      "      \"recurrent neural networks\",\n",
      "      \"long short-term memory\",\n",
      "      \"gated recurrent units\",\n",
      "      \"convolutional neural networks\",\n",
      "      \"bert\",\n",
      "      \"gpt\"\n",
      "    ],\n",
      "    \"topic modeling\": [\n",
      "      \"latent dirichlet allocation\",\n",
      "      \"non-negative matrix factorization\",\n",
      "      \"latent semantic analysis\",\n",
      "      \"correlational correspondence analysis\"\n",
      "    ]\n",
      "  },\n",
      "  \"image data\": {\n",
      "    \"image classification\": [\n",
      "      \"convolutional neural networks\",\n",
      "      \"resnet\",\n",
      "      \"inception\",\n",
      "      \"vgg\",\n",
      "      \"mobilenet\",\n",
      "      \"efficientnet\",\n",
      "      \"densenet\",\n",
      "      \"xception\",\n",
      "      \"nasnet\"\n",
      "    ],\n",
      "    \"image segmentation\": [\n",
      "      \"fully convolutional networks\",\n",
      "      \"u-net\",\n",
      "      \"mask r-cnn\",\n",
      "      \"deeplab\",\n",
      "      \"pspnet\",\n",
      "      \"hrnet\"\n",
      "    ],\n",
      "    \"object detection\": [\n",
      "      \"r-cnn\",\n",
      "      \"fast r-cnn\",\n",
      "      \"faster r-cnn\",\n",
      "      \"yolo\",\n",
      "      \"ssd\",\n",
      "      \"retinanet\",\n",
      "      \"centernet\",\n",
      "      \"efficientdet\"\n",
      "    ],\n",
      "    \"image captioning\": [\n",
      "      \"encoder-decoder architectures\",\n",
      "      \"attention models\",\n",
      "      \"show and tell\",\n",
      "      \"show, attend and tell\",\n",
      "      \"adaptive attention\",\n",
      "      \"transformer models\"\n",
      "    ],\n",
      "    \"style transfer\": [\n",
      "      \"neural style transfer\",\n",
      "      \"cyclegan\",\n",
      "      \"stargan\",\n",
      "      \"adain\"\n",
      "    ],\n",
      "    \"generative models\": [\n",
      "      \"autoencoders\",\n",
      "      \"variational autoencoders\",\n",
      "      \"generative adversarial networks\",\n",
      "      \"dcgan\",\n",
      "      \"wasserstein gan\",\n",
      "      \"cyclegan\",\n",
      "      \"stylegan\",\n",
      "      \"biggan\"\n",
      "    ]\n",
      "  },\n",
      "  \"audio data\": {\n",
      "    \"speech recognition\": [\n",
      "      \"hidden markov models\",\n",
      "      \"gaussian mixture models\",\n",
      "      \"deep neural networks\",\n",
      "      \"connectionist temporal classification\",\n",
      "      \"recurrent neural networks\",\n",
      "      \"long short-term memory\",\n",
      "      \"gated recurrent units\",\n",
      "      \"listen, attend, and spell\",\n",
      "      \"wavenet\",\n",
      "      \"tacotron\",\n",
      "      \"transformer models\"\n",
      "    ],\n",
      "    \"speaker identification/verification\": [\n",
      "      \"gaussian mixture models\",\n",
      "      \"support vector machines\",\n",
      "      \"i-vectors\",\n",
      "      \"deep speaker embeddings\",\n",
      "      \"recurrent neural networks\",\n",
      "      \"long short-term memory\",\n",
      "      \"gated recurrent units\"\n",
      "    ],\n",
      "    \"audio classification\": [\n",
      "      \"mel spectrogram\",\n",
      "      \"mfcc\",\n",
      "      \"convolutional neural networks\",\n",
      "      \"recurrent neural networks\",\n",
      "      \"long short-term memory\",\n",
      "      \"gated recurrent units\",\n",
      "      \"attention models\",\n",
      "      \"wavenet\",\n",
      "      \"spectrogram\"\n",
      "    ],\n",
      "    \"music generation\": [\n",
      "      \"markov models\",\n",
      "      \"restricted boltzmann machines\",\n",
      "      \"recurrent neural networks\",\n",
      "      \"long short-term memory\",\n",
      "      \"gated recurrent units\",\n",
      "      \"wavenet\",\n",
      "      \"transformer models\"\n",
      "    ],\n",
      "    \"music recommendation\": [\n",
      "      \"collaborative filtering\",\n",
      "      \"matrix factorization\",\n",
      "      \"autoencoders\",\n",
      "      \"restricted boltzmann machines\",\n",
      "      \"deep neural networks\",\n",
      "      \"recurrent neural networks\",\n",
      "      \"long short-term memory\",\n",
      "      \"gated recurrent units\"\n",
      "    ]\n",
      "  },\n",
      "  \"graph data\": {\n",
      "    \"graph networks\": [\n",
      "      \"graph convolutional networks\",\n",
      "      \"graphsage\",\n",
      "      \"graph attention networks\",\n",
      "      \"graph isomorphism networks\",\n",
      "      \"chebnet\",\n",
      "      \"ginconv\",\n",
      "      \"graph neural networks\",\n",
      "      \"dynamic graph representation learning\"\n",
      "    ],\n",
      "    \"graph clustering\": [\n",
      "      \"spectral clustering\",\n",
      "      \"graph modularity maximization\",\n",
      "      \"louvain algorithm\",\n",
      "      \"infomap\",\n",
      "      \"label propagation algorithm\"\n",
      "    ],\n",
      "    \"graph embeddings\": [\n",
      "      \"deepwalk\",\n",
      "      \"node2vec\",\n",
      "      \"graph convolutional network\",\n",
      "      \"structural deep network embeddings\",\n",
      "      \"ge-snmf\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = models_text\n",
    "lines = output.split(\"\\n\")\n",
    "for line_raw_case in lines:\n",
    "\n",
    "    line=line_raw_case.lower()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e4c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f1806e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3429157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38a34621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ObsidianGPT.cfg']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models={\n",
    "    \"numerical data\": {\n",
    "        \"regression\": [\"linear regression\", \"ridge regression\", \"lasso regression\", \"support vector machines\", \"decision trees\", \"random forest\", \"gradient boosting\", \"adaboost\", \"neural network\", \"k-nearest neighbors\"],\n",
    "        \"classification\": [\"logistic regression\", \"naive bayes\", \"support vector machines\", \"decision trees\", \"random forest\", \"gradient boosting\", \"adaboost\", \"k-nearest neighbors\", \"neural network\"],\n",
    "        \"clustering\": [\"k-means\", \"hierarchical clustering\", \"dbscan\", \"spectral clustering\", \"mean-shift\"],\n",
    "        \"dimensionality reduction\": [\"pca\", \"t-sne\", \"lda\", \"autoencoders\", \"umap\"]\n",
    "    },\n",
    "    \"categorical data\": {\n",
    "        \"regression\": [\"ordinal regression\", \"poisson regression\", \"negative binomial regression\"],\n",
    "        \"classification\": [\"logistic regression\", \"naive bayes\", \"support vector machines\", \"decision trees\", \"random forest\", \"gradient boosting\", \"adaboost\", \"k-nearest neighbors\", \"neural network\"],\n",
    "        \"clustering\": [\"k-modes\", \"latent class analysis\", \"hierarchical clustering\", \"dbscan\", \"spectral clustering\"],\n",
    "        \"association\": [\"apriori\", \"eclat\"]\n",
    "    },\n",
    "    \"text data\": {\n",
    "        \"classification\": [\"naive bayes\", \"support vector machines\", \"decision trees\", \"random forest\", \"gradient boosting\", \"adaboost\", \"k-nearest neighbors\", \"neural network\", \"convolutional neural networks (cnn)\", \"recurrent neural networks (rnn)\", \"long short-term memory networks (lstm)\", \"transformers\", \"bert\"],\n",
    "        \"clustering\": [\"k-means\", \"latent dirichlet allocation (lda)\", \"hierarchical clustering\", \"dbscan\"],\n",
    "        \"information retrieval\": [\"tf-idf\", \"latent semantic indexing (lsi)\", \"topic modeling\", \"word2vec\", \"glove\", \"bert\"],\n",
    "        \"sentiment analysis\": [\"naive bayes\", \"support vector machines\", \"lstm\", \"cnn\", \"bert\", \"transformers\"]\n",
    "    },\n",
    "    \"image data\": {\n",
    "        \"classification\": [\"neural network\", \"convolutional neural networks (cnn)\", \"transformers\", \"resnet\", \"inception\", \"vgg\", \"xception\", \"mobilenet\"],\n",
    "        \"object detection\": [\"r-cnn\", \"fast r-cnn\", \"faster r-cnn\", \"ssd\", \"yolo\"],\n",
    "        \"segmentation\": [\"u-net\", \"mask r-cnn\", \"fcn\", \"segnet\"],\n",
    "        \"image recognition\": [\"convolutional neural networks (cnn)\", \"transformers\", \"resnet\", \"inception\", \"vgg\", \"xception\", \"mobilenet\"],\n",
    "        \"face recognition\": [\"eigenfaces\", \"fisherfaces\", \"local binary patterns histograms (lbph)\", \"deepface\", \"facenet\", \"openface\"],\n",
    "        \"image synthesis\": [\"gan\", \"dcgan\"]\n",
    "    },\n",
    "    \"time-series data\": {\n",
    "        \"regression\": [\"arima\", \"sarima\", \"state space models\", \"holt-winters\", \"prophet\", \"lstm\"],\n",
    "        \"classification\": [\"neural network\", \"logistic regression\", \"k-nearest neighbors\", \"lstm\"],\n",
    "        \"forecasting\": [\"arima\", \"sarima\", \"exponential smoothing\", \"state space models\", \"holt-winters\", \"prophet\", \"lstm\"],\n",
    "        \"anomaly detection\": [\"arima\", \"sarima\", \"holt-winters\", \"prophet\", \"one-class svm\", \"isolation forest\",\"autoencoder\"]\n",
    "    },\n",
    "    \"sound data\": {\n",
    "        \"classification\": [\"neural network\", \"convolutional neural networks (cnn)\", \"recurrent neural networks (rnn)\", \"mel frequency cepstral coefficients (mfcc)\", \"lstm\"],\n",
    "        \"speech recognition\": [\"hidden markov models (hmm)\", \"deep speech\", \"wavenet\"],\n",
    "        \"sound synthesis\": [\"wavenet\", \"gan\"],\n",
    "        \"sound segmentation\": [\"hidden markov models (hmm)\", \"neural network\", \"lstm\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01d21be",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_ml_models = {\n",
    "    \"structured_data\": {\n",
    "        \"classification\": {\n",
    "            \"models\": [\"logistic regression\", \"decision trees\", \"random forest\", \"gradient boosting machines\", \"support vector machine\", \"xgboost\", \"lightgbm\", \"catboost\", \"neural networks\"],\n",
    "        },\n",
    "        \"regression\": {\n",
    "            \"models\": [\"linear regression\", \"decision trees\", \"random forest\", \"gradient boosting machines\", \"support vector regression\", \"xgboost\", \"lightgbm\", \"catboost\", \"neural networks\"],\n",
    "        },\n",
    "        \"clustering\": {\n",
    "            \"models\": [\"kmeans\", \"agglomerative clustering\", \"dbscan\", \"spectral clustering\", \"optics\", \"mean shift\",],\n",
    "        },\n",
    "        \"anomaly_detection\": {\n",
    "            \"models\": [\"isolation forest\", \"one-class svm\", \"local outlier factor\", \"autoencoders\"],\n",
    "        }\n",
    "    },\n",
    "    \"unstructured_data\": {\n",
    "        \"text_data\": {\n",
    "            \"classification\": {\n",
    "                \"models\": [\"naive bayes\", \"svm\", \"random forest\", \"xgboost\", \"rnn\", \"cnn\", \"transformers(bert, gpt)\", \"fasttext\"],\n",
    "            },\n",
    "            \"clustering\": {\n",
    "                \"models\": [\"kmeans\", \"agglomerative clustering\", \"dbscan\", \"latent dirichlet allocation\"],\n",
    "            },\n",
    "            \"sequence_prediction\": {\n",
    "                \"models\": [\"rnn\", \"lstm\", \"gru\", \"transformers\"],\n",
    "            },\n",
    "            \"sentiment_analysis\": {\n",
    "                \"models\": [\"naive bayes\", \"svm\", \"cnn\", \"rnn\", \"bert\", \"roberta\", \"xlnet\"],\n",
    "            },\n",
    "        },\n",
    "        \"image_data\": {\n",
    "            \"classification\": {\n",
    "                \"models\": [\"cnn\", \"pretrained cnn (vgg16, resnet, inception, xception)\", \"capsule networks\", \"autoencoders\"],\n",
    "            },\n",
    "            \"object_detection\": {\n",
    "                \"models\": [\"r-cnn\", \"fast r-cnn\", \"faster r-cnn\", \"ssd\", \"yolo\", \"mask r-cnn\"],\n",
    "            },\n",
    "            \"segmentation\": {\n",
    "                \"models\": [\"u-net\", \"mask r-cnn\", \"fcn\", \"deeplab\"],\n",
    "            },\n",
    "            \"image_generation\": {\n",
    "                \"models\": [\"gan\", \"dcgan\", \"wgan\", \"cgan\", \"stylegan\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"time_series_data\": {\n",
    "        \"forecasting\": {\n",
    "            \"models\": [\"arima\", \"sarima\", \"prophet\", \"var\", \"ses\", \"holt-winters\", \"rnn\", \"lstm\", \"gru\"],\n",
    "        },\n",
    "        \"anomaly_detection\": {\n",
    "            \"models\": [\"arima\", \"prophet\", \"isolation forest\", \"autoencoders\", \"lstm\", \"gru\"],\n",
    "        },\n",
    "    },\n",
    "    \"reinforcement_learning\": {\n",
    "        \"models\": [\"q-learning\", \"deep q-learning\", \"policy gradient\", \"actor-critic\", \"reinforce\", \"a3c\", \"a2c\", \"ppo\", \"ddpg\", \"td3\", \"sac\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba3bda",
   "metadata": {},
   "source": [
    "## Clean model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "89cc810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save models dict to disk with current date\n",
    "with open(f'models_{today.date()}.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(full_model_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT output is too variable, let's try again with our models extracted yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23b0314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file from disk if necessary\n",
    "filename = f'models_2023-09-05.txt'\n",
    "with open(filename, 'r') as read_file:\n",
    "    full_model_list = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba2c92d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'linear regression',\n",
       "  'model_type': 'regression models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'polynomial regression',\n",
       "  'model_type': 'regression models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'ridge regression',\n",
       "  'model_type': 'regression models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'lasso regression',\n",
       "  'model_type': 'regression models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'support vector regression',\n",
       "  'model_type': 'regression models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'logistic regression',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'k-nearest neighbors',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'support vector machines',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'decision trees',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'random forest',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'naive bayes',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'decision trees',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'random forest',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'gradient boosting',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'catboost',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'xgboost',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'lightgbm',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'bag-of-words',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'tf-idf',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'word2vec',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'fasttext',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'glove',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'lstm',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'gru',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'transformer',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'bert',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'gpt-3',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'cnn',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'lenet',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'alexnet',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'googlenet',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'vgg16',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'resnet',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'yolo',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'ssd',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'gan',\n",
       "  'model_type': 'image generation models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'dcgan',\n",
       "  'model_type': 'image generation models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'stylegan',\n",
       "  'model_type': 'image generation models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'cyclegan',\n",
       "  'model_type': 'image generation models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'pix2pix',\n",
       "  'model_type': 'image generation models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'arima',\n",
       "  'model_type': 'forecasting models',\n",
       "  'data_type': 'time series data'},\n",
       " {'name': 'sarima',\n",
       "  'model_type': 'forecasting models',\n",
       "  'data_type': 'time series data'},\n",
       " {'name': 'fb prophet',\n",
       "  'model_type': 'forecasting models',\n",
       "  'data_type': 'time series data'},\n",
       " {'name': 'lstm',\n",
       "  'model_type': 'forecasting models',\n",
       "  'data_type': 'time series data'},\n",
       " {'name': 'gru',\n",
       "  'model_type': 'forecasting models',\n",
       "  'data_type': 'time series data'},\n",
       " {'name': 'transformer',\n",
       "  'model_type': 'forecasting models',\n",
       "  'data_type': 'time series data'},\n",
       " {'name': 'hidden markov model',\n",
       "  'model_type': 'speech recognition models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'cnn',\n",
       "  'model_type': 'speech recognition models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'lstm',\n",
       "  'model_type': 'speech recognition models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'gru',\n",
       "  'model_type': 'speech recognition models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'deepspeech',\n",
       "  'model_type': 'speech recognition models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'rnn',\n",
       "  'model_type': 'music generation models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'lstm',\n",
       "  'model_type': 'music generation models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'wavenet',\n",
       "  'model_type': 'music generation models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'musegan',\n",
       "  'model_type': 'music generation models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'q-learning',\n",
       "  'model_type': 'model-free algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'sarsa',\n",
       "  'model_type': 'model-free algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'deep q-learning',\n",
       "  'model_type': 'model-free algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'ddpg',\n",
       "  'model_type': 'model-free algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'ppo',\n",
       "  'model_type': 'model-free algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'a3c',\n",
       "  'model_type': 'model-free algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'monte carlo tree search',\n",
       "  'model_type': 'model-based algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'dyna-q',\n",
       "  'model_type': 'model-based algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'pilco',\n",
       "  'model_type': 'model-based algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'k-means',\n",
       "  'model_type': 'clustering models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'dbscan',\n",
       "  'model_type': 'clustering models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'hierarchical clustering',\n",
       "  'model_type': 'clustering models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'spectral clustering',\n",
       "  'model_type': 'clustering models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'mean-shift',\n",
       "  'model_type': 'clustering models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'pca',\n",
       "  'model_type': 'dimensionality reduction models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 't-sne',\n",
       "  'model_type': 'dimensionality reduction models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'umap',\n",
       "  'model_type': 'dimensionality reduction models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'autoencoders',\n",
       "  'model_type': 'dimensionality reduction models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'factor analysis',\n",
       "  'model_type': 'dimensionality reduction models',\n",
       "  'data_type': 'unstructured data'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7dbf9",
   "metadata": {},
   "source": [
    "## Add data to existing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "82df47eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-05\n"
     ]
    }
   ],
   "source": [
    "print(today.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "789b85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit of history \n",
    "# On the 2023-05-05, the cell below cost 4$ in GPT4 API calls, and took 4 hours to execute\n",
    "# On the 2023-09-05,ITS BROKEN. So the cell below cost 0.51$ in GPT4 API calls, and took 19 minutes to execute\n",
    "# On the 2023-09-06, ITS BROKEN, does not create an entry for each model. It bunches them up in one entry under model type. The cell below cost 0.82$ in GPT4 API calls, and took 24 minutes to execute\n",
    "# On the 2023-09-06, it works again! The cell below cost 3.5$ in GPT4 API calls, and took 1h24 minutes to execute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652cbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2479e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                        | 1/74 [00:55<1:07:40, 55.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Description:\n",
      "Linear regression is a fundamental type of predictive analysis which is used to understand the relationship between two or more variables. The variable we want to predict is called the dependent variable (or sometimes, the outcome, target). The variables we use to predict the value of the dependent variable are called the independent variables (or sometimes, the predictors, inputs, regressors).\n",
      "\n",
      "2. Pros and Cons:\n",
      "   Pros:\n",
      "   - Simple to understand and interpret.\n",
      "   - Little to no tuning required.\n",
      "   - Fast to model and predict.\n",
      "   - Works best with numerical continuous data.\n",
      "   \n",
      "   Cons:\n",
      "   - It assumes linear relationship between independent and dependent variables.\n",
      "   - It can be adversely affected by outliers.\n",
      "   - Linear regression may over-simplify real-world problems by assuming a linear relationship among the variables.\n",
      "\n",
      "3. Use Cases:\n",
      "   - Predicting sales amount given advertising budgets in different venues (TV, Radio, Newspapers).\n",
      "   - Predicting house prices given house features such as number of rooms, size, and location.\n",
      "   - Prediction of student's grades based on factors such as attendance, number of hours studied etc.\n",
      "\n",
      "4. Resources:\n",
      "   - [Linear Regression in Python with Scikit-Learn](https://realpython.com/linear-regression-in-python/)\n",
      "   - [A Gentle Introduction to Linear Regression With Maximum Likelihood Estimation](https://machinelearningmastery.com/linear-regression-with-maximum-likelihood-estimation/)\n",
      "   - [Complete Guide To Linear Regression In Python](https://towardsdatascience.com/complete-guide-to-linear-regression-in-python-80ce5e551b17)\n",
      "\n",
      "5. Python Code:\n",
      "```python\n",
      "   from sklearn.model_selection import train_test_split \n",
      "   from sklearn.linear_model import LinearRegression\n",
      "   from sklearn import metrics\n",
      "   import numpy as np\n",
      "   import matplotlib.pyplot as plt\n",
      "   import pandas as pd\n",
      "     \n",
      "   # Load dataset\n",
      "   dataset = pd.read_csv('dataset.csv')\n",
      "   X = dataset['Independent_Variable'].values.reshape(-1,1)\n",
      "   y = dataset['Dependent_Variable'].values.reshape(-1,1)\n",
      "   \n",
      "   # Split data into training and test sets\n",
      "   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
      "   \n",
      "   # Training the algorithm\n",
      "   regressor = LinearRegression()\n",
      "   regressor.fit(X_train, y_train)\n",
      "   \n",
      "   # Making predictions using the model\n",
      "   y_pred = regressor.predict(X_test)\n",
      "\n",
      "   # Plotting the results\n",
      "   plt.scatter(X_test, y_test, color='black')\n",
      "   plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
      "   plt.show()\n",
      "```\n",
      "6. Expertise:\n",
      "   - Andrew Ng - [LinkedIn Profile](https://www.linkedin.com/in/andrewyng/)\n",
      "   - Sebastian Raschka - [Github Profile](https://github.com/rasbt)\n",
      "   - Chris Albon - [Github Profile](https://github.com/chrisalbon)\n",
      "   - Jason Brownlee - [Github Profile](https://github.com/jbrownlee)\n",
      "   - Trevor Hastie - [Github Profile](https://github.com/trevorhastie)\n",
      "   \n",
      "Please note that Github or LinkedIn profiles might not fully reflect the individual's expertise in a specific area like linear regression. The list above is compiled based on their broader contributions in the field of machine learning and data science.\n",
      "Variable written to linear regression_numerical data.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▌                                                       | 2/74 [01:54<1:09:09, 57.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Description:\n",
      "The Polynomial Regression model is a type of regression analysis in which the relationship between the independent variable x and the dependent variable y is modeled as an nth degree polynomial. It expands the linear model by adding extra predictors, obtained by raising each of the original predictors to a power. Polynomial regression fits a nonlinear relationship between the value of x and the corresponding conditional mean of y, denoted E(y |x).\n",
      "\n",
      "2. Pros and Cons:\n",
      "\n",
      "Pros:\n",
      "- Polynomial regression models can fit a wider range of data than linear regression, as they can model relationships that change in direction.\n",
      "- With high-degree polynomials, you can fit nearly any shape dataset.\n",
      "- They're great for modeling curves and other complex data shapes.\n",
      "\n",
      "Cons:\n",
      "- Polynomial regression models can overfit data easily, leading to high-variance models that do not generalize well to future data.\n",
      "- The addition of too many polynomial terms can greatly enlarge the amount of collinearity in the model, making it difficult to interpret.\n",
      "- The use of high degree polynomial regression can result in the model oscillating between points causing unrealistic predictions.\n",
      "\n",
      "3. Use Cases:\n",
      "- Polynomial regression is commonly used in financial forecasting, where trends may not be linear but could follow some polynomial order, e.g., the prediction of stock prices.\n",
      "- It can be used in a physical sciences context where relationships might inherently be polynomial, e.g., in electronics or mechanics.\n",
      "- It's also used in machine learning algorithms that need to model relationships between variables accurately, such as support vector machines or neural networks.\n",
      "\n",
      "4. Resources for implementation:\n",
      "- [Polynomial Regression Explained](https://www.datacamp.com/community/tutorials/polynomial-regression)\n",
      "- [Polynomial Regression in Python](https://towardsdatascience.com/machine-learning-polynomial-regression-with-python-5328e4e8a386)\n",
      "- [Polynomial Regression in Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
      "\n",
      "5. Code sample:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.preprocessing import PolynomialFeatures\n",
      "\n",
      "# Generate x and y vectors\n",
      "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "y = np.array([2, 3, 5, 7, 11, 13, 17, 19, 23])\n",
      "\n",
      "# We transform our matrix of input x into a matrix of higher degree polynomials of x\n",
      "poly = PolynomialFeatures(degree = 3, include_bias = False)\n",
      "x_poly = poly.fit_transform(x.reshape(-1, 1))\n",
      "\n",
      "# Perform linear regression with our new matrix of predictors\n",
      "lm = LinearRegression()\n",
      "lm.fit(x_poly, y)\n",
      "\n",
      "# Now we can use lm to predict y values\n",
      "y_predicted = lm.predict(x_poly)\n",
      "```\n",
      "\n",
      "6. Experts:\n",
      "   - [Andrew Ng](https://www.andrewng.org/), he is a Professor at Stanford University, Co-founder of Coursera and the founder of Google Brain and Landing AI.\n",
      "   - [Yoshua Bengio](https://ca.linkedin.com/in/yoshua-bengio-4102183), he is the head of the Montreal Institute for Learning Algorithms (MILA).\n",
      "   - Trevor Hastie, is a Professor at Stanford University and is involved in the development of Scikit-Learn [(GitHub)](https://github.com/trevorhastie).\n",
      "   - [Sebastian Raschka](https://www.linkedin.com/in/sebastianraschka/), he is a machine learning educator and author of \"Python Machine Learning\" book.\n",
      "   - [Jake VanderPlas](https://github.com/jakevdp), he is a Director of Open Software at University of Washington's Data Science Centre, with a focus on Python and Machine Learning.\n",
      "Variable written to polynomial regression_numerical data.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▌                                                       | 2/74 [02:24<1:26:50, 72.37s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:12\u001b[0m\n",
      "Cell \u001b[0;32mIn [5], line 3\u001b[0m, in \u001b[0;36mgenerate_text\u001b[0;34m(prompt, GPTmodel)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_text\u001b[39m(prompt, GPTmodel):\n\u001b[0;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGPTmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/human/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/human/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/human/lib/python3.10/site-packages/openai/api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/human/lib/python3.10/site-packages/openai/api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m     _thread_context\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m _make_session()\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/human/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/human/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/human/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/human/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/human/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/human/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models_with_details=full_model_list.copy()\n",
    "for model in tqdm(models_with_details):\n",
    "    resource_prompt = f\"\"\"\n",
    "    For the {model['name']} model with {model['data_type']} , provide:\n",
    "    1. A short description of the model.\n",
    "    2. A list of the pros and cons of the model.\n",
    "    3. The three most relevant use cases.\n",
    "    4. Three great resources with relevant internet links for implementing the model.\n",
    "    5. The top 5 people with the most expertise relative to this model, with a link to their github or linkedin page\n",
    "    \"\"\"\n",
    "    resources = generate_text(resource_prompt, GPTmodel=\"gpt-4-0314\")\n",
    "    # If debugging, uncomment line below\n",
    "    print(resources)\n",
    "    \n",
    "    # Specify the file path where you want to create the text file\n",
    "    file_path = f\"{model['name']}_{model['data_type']}.txt\"\n",
    "    \n",
    "    # Call the function to write the variable to the file\n",
    "    write_variable_to_text_file(resources, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintenant qu'on a écrit les fichiers sur le disque on peut en extraire plus proprement les infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3782224e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'linear regression',\n",
       " 'model_type': 'regression models',\n",
       " 'data_type': 'numerical data',\n",
       " 'resources': ' Useful Resources:',\n",
       " 'python_code': '```',\n",
       " 'description': '1. Description:',\n",
       " 'pros_cons': ' Pros and Cons:',\n",
       " 'top5': \" Top 5 People:Due to privacy issues, it's not entirely ethical to provide direct links to individual profiles. As such, I don't have direct links to individuals' professional profiles per se. However, these are the top five individuals (Researchers or Professors) related to Factor Analysis:\\n\\n- Karl Jöreskog: Developer of LISREL, a software package used for structural equation modeling, which includes Factor Analysis.\\n- Peter M Bentler: Developer of EQS, a structural equation model software package which includes factor analysis.\\n- Robert Cudeck: Has published numerous papers on Factor Analysis.\\n- Joop Hox: Wrote several publications on multilevel factor analysis.\\n- Fan Zhang: Has written several academic papers on Factor Analysis.\\n\",\n",
       " 'use_cases': ' Relevant Use Cases:'}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "760702b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'linear regression',\n",
       "  'model_type': 'regression models',\n",
       "  'data_type': 'numerical data',\n",
       "  'resources': ' Useful Resources:',\n",
       "  'python_code': '```',\n",
       "  'description': '1. Description:',\n",
       "  'pros_cons': ' Pros and Cons:',\n",
       "  'top5': \" Top 5 People:Due to privacy issues, it's not entirely ethical to provide direct links to individual profiles. As such, I don't have direct links to individuals' professional profiles per se. However, these are the top five individuals (Researchers or Professors) related to Factor Analysis:\\n\\n- Karl Jöreskog: Developer of LISREL, a software package used for structural equation modeling, which includes Factor Analysis.\\n- Peter M Bentler: Developer of EQS, a structural equation model software package which includes factor analysis.\\n- Robert Cudeck: Has published numerous papers on Factor Analysis.\\n- Joop Hox: Wrote several publications on multilevel factor analysis.\\n- Fan Zhang: Has written several academic papers on Factor Analysis.\\n\",\n",
       "  'use_cases': ' Relevant Use Cases:'}]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_with_details[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62628297",
   "metadata": {},
   "source": [
    "## Save and/or reload the detailed models dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f567ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's save our dictionnary of enriched models to disk with the current date attached\n",
    "with open(f'models_with_details_{datetime.datetime.now().date()}.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(models_with_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "94460907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file from disk if necessary\n",
    "filename = f'models_with_details_{datetime.datetime.now().date()}.txt'\n",
    "with open(filename, 'r') as read_file:\n",
    "    models_with_details = json.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855be02d",
   "metadata": {},
   "source": [
    "## Parsing the detailed models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f6bc13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'linear regression',\n",
       "  'model_type': 'regression models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'polynomial regression',\n",
       "  'model_type': 'regression models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'ridge regression',\n",
       "  'model_type': 'regression models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'lasso regression',\n",
       "  'model_type': 'regression models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'support vector regression',\n",
       "  'model_type': 'regression models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'logistic regression',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'k-nearest neighbors',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'support vector machines',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'decision trees',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'random forest',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'numerical data'},\n",
       " {'name': 'naive bayes',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'decision trees',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'random forest',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'gradient boosting',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'catboost',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'xgboost',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'lightgbm',\n",
       "  'model_type': 'classification models',\n",
       "  'data_type': 'categorical data'},\n",
       " {'name': 'bag-of-words',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'tf-idf',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'word2vec',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'fasttext',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'glove',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'lstm',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'gru',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'transformer',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'bert',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'gpt-3',\n",
       "  'model_type': 'natural language processing models',\n",
       "  'data_type': 'text data'},\n",
       " {'name': 'cnn',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'lenet',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'alexnet',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'googlenet',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'vgg16',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'resnet',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'yolo',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'ssd',\n",
       "  'model_type': 'computer vision models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'gan',\n",
       "  'model_type': 'image generation models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'dcgan',\n",
       "  'model_type': 'image generation models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'stylegan',\n",
       "  'model_type': 'image generation models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'cyclegan',\n",
       "  'model_type': 'image generation models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'pix2pix',\n",
       "  'model_type': 'image generation models',\n",
       "  'data_type': 'image data'},\n",
       " {'name': 'arima',\n",
       "  'model_type': 'forecasting models',\n",
       "  'data_type': 'time series data'},\n",
       " {'name': 'sarima',\n",
       "  'model_type': 'forecasting models',\n",
       "  'data_type': 'time series data'},\n",
       " {'name': 'fb prophet',\n",
       "  'model_type': 'forecasting models',\n",
       "  'data_type': 'time series data'},\n",
       " {'name': 'lstm',\n",
       "  'model_type': 'forecasting models',\n",
       "  'data_type': 'time series data'},\n",
       " {'name': 'gru',\n",
       "  'model_type': 'forecasting models',\n",
       "  'data_type': 'time series data'},\n",
       " {'name': 'transformer',\n",
       "  'model_type': 'forecasting models',\n",
       "  'data_type': 'time series data'},\n",
       " {'name': 'hidden markov model',\n",
       "  'model_type': 'speech recognition models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'cnn',\n",
       "  'model_type': 'speech recognition models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'lstm',\n",
       "  'model_type': 'speech recognition models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'gru',\n",
       "  'model_type': 'speech recognition models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'deepspeech',\n",
       "  'model_type': 'speech recognition models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'rnn',\n",
       "  'model_type': 'music generation models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'lstm',\n",
       "  'model_type': 'music generation models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'wavenet',\n",
       "  'model_type': 'music generation models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'musegan',\n",
       "  'model_type': 'music generation models',\n",
       "  'data_type': 'audio data'},\n",
       " {'name': 'q-learning',\n",
       "  'model_type': 'model-free algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'sarsa',\n",
       "  'model_type': 'model-free algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'deep q-learning',\n",
       "  'model_type': 'model-free algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'ddpg',\n",
       "  'model_type': 'model-free algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'ppo',\n",
       "  'model_type': 'model-free algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'a3c',\n",
       "  'model_type': 'model-free algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'monte carlo tree search',\n",
       "  'model_type': 'model-based algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'dyna-q',\n",
       "  'model_type': 'model-based algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'pilco',\n",
       "  'model_type': 'model-based algorithms',\n",
       "  'data_type': 'reinforcement learning'},\n",
       " {'name': 'k-means',\n",
       "  'model_type': 'clustering models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'dbscan',\n",
       "  'model_type': 'clustering models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'hierarchical clustering',\n",
       "  'model_type': 'clustering models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'spectral clustering',\n",
       "  'model_type': 'clustering models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'mean-shift',\n",
       "  'model_type': 'clustering models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'pca',\n",
       "  'model_type': 'dimensionality reduction models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 't-sne',\n",
       "  'model_type': 'dimensionality reduction models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'umap',\n",
       "  'model_type': 'dimensionality reduction models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'autoencoders',\n",
       "  'model_type': 'dimensionality reduction models',\n",
       "  'data_type': 'unstructured data'},\n",
       " {'name': 'factor analysis',\n",
       "  'model_type': 'dimensionality reduction models',\n",
       "  'data_type': 'unstructured data'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_with_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "10688aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'linear regression',\n",
       " 'model_type': 'regression models',\n",
       " 'data_type': 'numerical data',\n",
       " 'resources': \"1. Short Description:\\nA linear regression model is a simple statistical tool used for predicting a quantitative response Y using a single or multiple predictor variable X. It predicts this output by fitting a linear equation to the observed data. The steps to perform the linear regression involve finding coefficients corresponding to the variables that minimize the difference between the predicted and true responses.\\n\\n2. Pros and Cons:\\n\\n   Pros:\\n   - Simple to understand and interpret\\n   - Requires less computational power\\n   - Useful for findings relationships between features and output\\n   \\n   Cons:\\n   - Assumes a linear relationship between variables\\n   - Prone to overfitting and underfitting\\n   - Sensitive to outliers\\n\\n3. Use Cases:\\n   - Predicting house prices based on various attributes such as the number of rooms, location, area, etc.\\n   - Predicting sales for a company based on advertising spend.\\n   - Predicting fuel consumption of a vehicle based on engine size.\\n\\n4. Resources:\\n   - [Scikit-Learn Linear Regression Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\\n   - [StatQuest: Linear Regression Video Tutorial](https://www.youtube.com/watch?v=nk2CQITm_eo)\\n   - [Practical Guide to Linear Regression in Python](https://realpython.com/linear-regression-in-python/)\\n\\n5. Python Code:\\n\\n   ```\\n   import pandas as pd\\n   from sklearn.model_selection import train_test_split \\n   from sklearn.linear_model import LinearRegression\\n   \\n   # Load the dataset\\n   dataset = pd.read_csv('data.csv')  \\n   \\n   X = dataset.iloc[:, :-1].values  \\n   y = dataset.iloc[:, 1].values  \\n   \\n   # Split the dataset into train and test data\\n   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  \\n   \\n   # Train the model\\n   regressor = LinearRegression()  \\n   regressor.fit(X_train, y_train) \\n   \\n   # Predict the values\\n   y_pred = regressor.predict(X_test) \\n   ```\\n\\n6. Experts:\\n   - [Andrew Ng](https://www.linkedin.com/in/andrewyng/)\\n   - [Leo Breiman](https://en.wikipedia.org/wiki/Leo_Breiman)\\n   - [Trevor Hastie](https://www.linkedin.com/in/trevor-hastie-948a06133/)\\n   - [Robert Tibshirani](https://www.linkedin.com/in/robert-tibshirani-54298b19/)\\n   - [Jerome Friedman](https://statweb.stanford.edu/~jhf/)\",\n",
       " 'python_code': '6. The top 5 people with the most expertise relative to this model:',\n",
       " 'description': \"1. A short description of the model:\\nThe Naive Bayes model for categorical data, also known as Multinomial Naive Bayes, is a classification technique based on Bayes' Theorem with a strong (naive) assumption of independence among features. Each feature is considered independent and contributes individually to predict the class of an event. The model calculates the probability of particular category given a list of features.\",\n",
       " 'pros_cons': ' A list of the pros and cons of the model:',\n",
       " 'top5': \"Considering that Naive Bayes is a classic algorithm in machine learning and statistics, it's challenging to point out specific experts. However, these people have made significant contributions to the field of machine learning:    - [Andrew Ng](www.linkedin.com/in/andrewyng)\\n    - [Yoshua Bengio](https://www.linkedin.com/in/yoshua-bengio-92004114)\\n    - [Yann LeCun](https://www.linkedin.com/in/yann-lecun-950936)\\n    - [Geoffrey Hinton](https://www.linkedin.com/in/geoffrey-hinton-38b8a914)\\n    - [Ian Goodfellow](https://www.linkedin.com/in/ian-goodfellow-a11619a)\\n\",\n",
       " 'use_cases': \" The three most relevant use cases:\\n    - Text classification/Spam Filtering: It's mostly used in text classification due to better result in multi class problems.\\n    - Sentiment Analysis: It is also used for sentiment analysis; positivity or negativity of a statement.\\n    - Recommendation system: The Naive Bayes model is also used in recommendation systems for predicting the likeliness of a user buying a product.\"}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_with_details[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d979c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Below is a bit too hackery, work in progress to make it more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3a7f3a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'linear regression',\n",
       "  'model_type': 'regression models',\n",
       "  'data_type': 'numerical data',\n",
       "  'resources': \"1. Short Description:\\nA linear regression model is a simple statistical tool used for predicting a quantitative response Y using a single or multiple predictor variable X. It predicts this output by fitting a linear equation to the observed data. The steps to perform the linear regression involve finding coefficients corresponding to the variables that minimize the difference between the predicted and true responses.\\n\\n2. Pros and Cons:\\n\\n   Pros:\\n   - Simple to understand and interpret\\n   - Requires less computational power\\n   - Useful for findings relationships between features and output\\n   \\n   Cons:\\n   - Assumes a linear relationship between variables\\n   - Prone to overfitting and underfitting\\n   - Sensitive to outliers\\n\\n3. Use Cases:\\n   - Predicting house prices based on various attributes such as the number of rooms, location, area, etc.\\n   - Predicting sales for a company based on advertising spend.\\n   - Predicting fuel consumption of a vehicle based on engine size.\\n\\n4. Resources:\\n   - [Scikit-Learn Linear Regression Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\\n   - [StatQuest: Linear Regression Video Tutorial](https://www.youtube.com/watch?v=nk2CQITm_eo)\\n   - [Practical Guide to Linear Regression in Python](https://realpython.com/linear-regression-in-python/)\\n\\n5. Python Code:\\n\\n   ```\\n   import pandas as pd\\n   from sklearn.model_selection import train_test_split \\n   from sklearn.linear_model import LinearRegression\\n   \\n   # Load the dataset\\n   dataset = pd.read_csv('data.csv')  \\n   \\n   X = dataset.iloc[:, :-1].values  \\n   y = dataset.iloc[:, 1].values  \\n   \\n   # Split the dataset into train and test data\\n   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  \\n   \\n   # Train the model\\n   regressor = LinearRegression()  \\n   regressor.fit(X_train, y_train) \\n   \\n   # Predict the values\\n   y_pred = regressor.predict(X_test) \\n   ```\\n\\n6. Experts:\\n   - [Andrew Ng](https://www.linkedin.com/in/andrewyng/)\\n   - [Leo Breiman](https://en.wikipedia.org/wiki/Leo_Breiman)\\n   - [Trevor Hastie](https://www.linkedin.com/in/trevor-hastie-948a06133/)\\n   - [Robert Tibshirani](https://www.linkedin.com/in/robert-tibshirani-54298b19/)\\n   - [Jerome Friedman](https://statweb.stanford.edu/~jhf/)\",\n",
       "  'python_code': '6. The top 5 people with the most expertise relative to this model:',\n",
       "  'description': \"1. A short description of the model:\\nThe Naive Bayes model for categorical data, also known as Multinomial Naive Bayes, is a classification technique based on Bayes' Theorem with a strong (naive) assumption of independence among features. Each feature is considered independent and contributes individually to predict the class of an event. The model calculates the probability of particular category given a list of features.\",\n",
       "  'pros_cons': ' A list of the pros and cons of the model:',\n",
       "  'top5': \"Considering that Naive Bayes is a classic algorithm in machine learning and statistics, it's challenging to point out specific experts. However, these people have made significant contributions to the field of machine learning:    - [Andrew Ng](www.linkedin.com/in/andrewyng)\\n    - [Yoshua Bengio](https://www.linkedin.com/in/yoshua-bengio-92004114)\\n    - [Yann LeCun](https://www.linkedin.com/in/yann-lecun-950936)\\n    - [Geoffrey Hinton](https://www.linkedin.com/in/geoffrey-hinton-38b8a914)\\n    - [Ian Goodfellow](https://www.linkedin.com/in/ian-goodfellow-a11619a)\\n\",\n",
       "  'use_cases': \" The three most relevant use cases:\\n    - Text classification/Spam Filtering: It's mostly used in text classification due to better result in multi class problems.\\n    - Sentiment Analysis: It is also used for sentiment analysis; positivity or negativity of a statement.\\n    - Recommendation system: The Naive Bayes model is also used in recommendation systems for predicting the likeliness of a user buying a product.\"}]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_with_details[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9c0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "963e09e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'linear regression', 'model_type': 'regression models', 'data_type': 'numerical data', 'resources': ' Useful Resources:', 'python_code': '```', 'description': '1. Description:', 'pros_cons': ' Pros and Cons:', 'top5': \" Top 5 People:Due to privacy issues, it's not entirely ethical to provide direct links to individual profiles. As such, I don't have direct links to individuals' professional profiles per se. However, these are the top five individuals (Researchers or Professors) related to Factor Analysis:\\n\\n- Karl Jöreskog: Developer of LISREL, a software package used for structural equation modeling, which includes Factor Analysis.\\n- Peter M Bentler: Developer of EQS, a structural equation model software package which includes factor analysis.\\n- Robert Cudeck: Has published numerous papers on Factor Analysis.\\n- Joop Hox: Wrote several publications on multilevel factor analysis.\\n- Fan Zhang: Has written several academic papers on Factor Analysis.\\n\", 'use_cases': ' Relevant Use Cases:'}\n",
      "CPU times: user 410 µs, sys: 200 µs, total: 610 µs\n",
      "Wall time: 461 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for model in models_with_details[0:1]:\n",
    "    print(model)\n",
    "    output = resources\n",
    "    parsed_output = {}\n",
    "    keys = [\"description\", \"pros_cons\", \"use_cases\", \"resources\", \"python_code\", \"top5\"]\n",
    "\n",
    "    lines = output.split(\"\\n\")\n",
    "    current_key = \"\"\n",
    "    \n",
    "   \n",
    "    # Print the parsed output\n",
    "    for key, value in parsed_output.items():\n",
    "        model[key]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86688cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74ad958c",
   "metadata": {},
   "source": [
    "## Write to Obsidian Vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bfefdb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the models list\n",
    "for model in models_with_details:\n",
    "    model_filename = f\"{model['name']}.md\"\n",
    "    model_filepath = os.path.join(vault_path, model_filename)\n",
    "    data_type = model['data_type']\n",
    "    model_name = model['name']\n",
    "\n",
    "    # Create the directory for the data type if it does not exist\n",
    "    data_type_path = os.path.join(vault_path, data_type)\n",
    "    if not os.path.exists(data_type_path):\n",
    "        os.makedirs(data_type_path)\n",
    "\n",
    "    # Create a file for the model and write its information\n",
    "    file_name = f\"{model_name}.md\"\n",
    "    file_path = os.path.join(data_type_path, file_name)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        \n",
    "        f.write(f\"**Model Type:** {model['model_type']}\\n\")\n",
    "        f.write(f\"**Data Type:** {model['data_type']}\\n\\n\")\n",
    "        \n",
    "        # Add additional information about the model if available\n",
    "        if 'use_cases' in model:\n",
    "            f.write(\"## Use Cases :\\n\\n\")\n",
    "            for use_case in model['use_cases']:\n",
    "                f.write(use_case +\"\\n\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        #f.write(f\"**Description**:\\n\\n{model['description']}\\n\\n\") # Description field is not correct, commented for now\n",
    "        \n",
    "        f.write(f\"## Python code: \\n{model['python_code']}\\n\\n\")\n",
    "        \n",
    "        # Add additional information about the model if available\n",
    "        if 'resources' in model:\n",
    "            f.write(\"## Resources\\n\\n\")\n",
    "            for resource in model['resources']:\n",
    "                f.write(resource +\"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        # Add \"See Also\" section with links to related models\n",
    "        f.write(f\"**See Also**:\\n\\n\")\n",
    "        for other_model in models:\n",
    "            if other_model['name'] != model['name'] and other_model['data_type'] == model['data_type']:\n",
    "                f.write(f\"- [[{other_model['name']}]]\\n\")\n",
    "\n",
    "\n",
    "        # Add relevant tags with hierarchy. Strip special chars for clarity\n",
    "        f.write(f\"\\n---\\n\")\n",
    "        root_tag = model['data_type'].replace(' ', '').lower()\n",
    "        leaf_tag = model['name'].replace('(', '').replace(')', '').replace(' ', '').lower()\n",
    "        f.write(f\"tags: #{root_tag}, #{root_tag}/{leaf_tag}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d456d4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

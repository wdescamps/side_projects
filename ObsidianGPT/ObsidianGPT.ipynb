{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f234c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b4cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import requests\n",
    "import openai\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea324d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API key stored in local cfg file\n",
    "# How to is available here : https://towardsdatascience.com/keeping-credentials-safe-in-jupyter-notebooks-fbd215a8e311\n",
    "\n",
    "parser = ConfigParser()\n",
    "_ = parser.read('ObsidianGPT.cfg')\n",
    "openai.api_key = parser.get('my_api', 'auth_key')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e4314c3",
   "metadata": {},
   "source": [
    "#Show available OPENAI models\n",
    "for i in openai.Model.list()[\"data\"]:\n",
    "    print(i[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc36b2",
   "metadata": {},
   "source": [
    "# Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d576a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt):\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55b8f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_obsidian_vault(vault_name, parent_directory):\n",
    "    vault_path = os.path.join(parent_directory, vault_name)\n",
    "    \n",
    "    # Create the vault directory\n",
    "    os.makedirs(vault_path, exist_ok=True)\n",
    "\n",
    "    # Create default folders within the vault\n",
    "    os.makedirs(os.path.join(vault_path, \"attachments\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(vault_path, \"notes\"), exist_ok=True)\n",
    "    \n",
    "    return vault_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4db4f",
   "metadata": {},
   "source": [
    "# Create and/or modify a local obsidian vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4574a269",
   "metadata": {},
   "outputs": [],
   "source": [
    "vault_name = \"MyNewVault\"\n",
    "parent_directory = os.getcwd()\n",
    "vault_path = create_obsidian_vault(vault_name, parent_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51859d3d",
   "metadata": {},
   "source": [
    "## Prompt created by GPT, asking him to create a prompt to match my input of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of models for different kinds of data from the GPT API\n",
    "models_prompt = \"\"\"\n",
    "Provide a list of popular machine learning and deep learning models for different types of data, \n",
    "grouped by data type and problem type. Include Numerical Data with Regression and Classification models, \n",
    "Categorical Data with Classification models, Text Data with Natural Language Processing models, \n",
    "Image Data with Computer Vision models and Image Generation models, Time Series Data with Forecasting models, \n",
    "Audio Data with Speech Recognition and Music Generation models, Reinforcement Learning with Model-free \n",
    "and Model-based Algorithms, and Unstructured Data with Clustering and Dimensionality Reduction models.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f34eaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT API Call\n",
    "raw_models_response = generate_text(models_prompt)\n",
    "models_text = raw_models_response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba3bda",
   "metadata": {},
   "source": [
    "## Clean model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f652bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "current_data_type = None\n",
    "\n",
    "for line in models_text.split('\\n'):\n",
    "    line = line.strip()\n",
    "    \n",
    "    if not line:\n",
    "        continue\n",
    "    \n",
    "    if line.endswith(':'):\n",
    "        current_data_type = line[:-1]\n",
    "    else:\n",
    "        model_name = line.lstrip('- ')\n",
    "        models.append({\"name\": model_name, \"data_type\": current_data_type})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7dbf9",
   "metadata": {},
   "source": [
    "## Add data to existing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2479e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    resource_prompt = f\"\"\"\n",
    "    For the {model['name']} model, provide:\n",
    "    1. A brief description of the model.\n",
    "    2. The three most relevant use cases.\n",
    "    3. Three great resources with relevant internet links for implementing the model.\n",
    "    \"\"\"\n",
    "    raw_resource_response = generate_text(resource_prompt)\n",
    "    resources = raw_resource_response.choices[0].message.content.strip()\n",
    "    model[\"resources\"] = resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ad958c",
   "metadata": {},
   "source": [
    "## Write to Obsidian Vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83cb6d6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'description'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(model_filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**Data Type**: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**Description**:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Add \"See Also\" section with links to related models\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**See Also**:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'description'"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model_filename = f\"{model['name']}.md\"\n",
    "    model_filepath = os.path.join(vault_path, model_filename)\n",
    "\n",
    "    with open(model_filepath, \"w\") as f:\n",
    "        f.write(f\"**Data Type**: {model['data_type']}\\n\\n\")\n",
    "        f.write(f\"**Description**:\\n\\n{model['description']}\\n\\n\")\n",
    "\n",
    "        # Add \"See Also\" section with links to related models\n",
    "        f.write(f\"**See Also**:\\n\\n\")\n",
    "        for other_model in models:\n",
    "            if other_model['name'] != model['name'] and other_model['data_type'] == model['data_type']:\n",
    "                f.write(f\"- [[{other_model['name']}]]\\n\")\n",
    "\n",
    "        # Add \"Python Resources\" section\n",
    "        f.write(f\"**Python Resources**:\\n\\n{model['resources']}\\n\\n\")\n",
    "\n",
    "        # Add relevant tags with hierarchy, strip special chars for clarity\n",
    "        f.write(f\"\\n---\\n\")\n",
    "        root_tag = model['data_type'].replace(' ', '-').lower()\n",
    "        leaf_tag = model['name'].replace('(', '').replace(')', '').replace(' ', '-').lower()\n",
    "        f.write(f\"tags: #{root_tag}, #{root_tag}/{leaf_tag}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfefdb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

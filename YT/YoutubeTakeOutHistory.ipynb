{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e69492",
   "metadata": {},
   "source": [
    "# READ ME "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a501beb",
   "metadata": {},
   "source": [
    "## Necessary Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a930606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install html5lib\n",
    "#!pip install python-youtube    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf8fe2",
   "metadata": {},
   "source": [
    "##  Necessary API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96458ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ce notebook nécessite une clé API gratuite pour l'api Youtube V3\n",
    "# Il suffit de la demander sur ce lien : https://console.cloud.google.com/apis/api/youtube.googleapis.com/\n",
    "# La doc est ici : https://developers.google.com/youtube/v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4573b3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cb6d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:54:32.848594Z",
     "start_time": "2023-02-21T12:54:31.110177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from configparser import ConfigParser\n",
    "from datetime import datetime\n",
    "from pyyoutube import Api\n",
    "import locale\n",
    "import requests\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import pickle\n",
    "import isodate\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e94b54",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you're new to scraping data, a good guide can be found here : https://towardsdatascience.com/all-pandas-read-html-you-should-know-for-scraping-data-from-html-tables-a3cbb5ce8274"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e760737",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c0a77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:54:32.871821Z",
     "start_time": "2023-02-21T12:54:32.865613Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def parse_html_document(soup_loc):\n",
    "    #Parse the HTML document\n",
    "    full_dic = {}\n",
    "\n",
    "    for i in soup_loc.find_all(\n",
    "            class_=\n",
    "            'content-cell mdl-cell mdl-cell--6-col mdl-typography--body-1'):\n",
    "        i.find_all(name='a')\n",
    "\n",
    "        date_ = i.contents[-1]\n",
    "\n",
    "        #loop to find the 2 links in a given bracket\n",
    "        for j in i.find_all(name='a'):\n",
    "            #Parfois il n'y a pas de channel name... donc je met ces deux variables défaut et je teste dans le if\n",
    "            channel_url = None\n",
    "            channel_name = None\n",
    "            #tester si on a les infos pour les channels\n",
    "            if \"channel\" in j.get(\"href\"):\n",
    "                #lien \"channel\"\n",
    "                channel_url = j.get(\"href\")\n",
    "                #condition pour virer une erreur bizarre de \"list index out of range\"\n",
    "                if len(i.find_all(name='a')) == 2:\n",
    "                    #Add channel name\n",
    "                    channel_name = i.find_all(name='a')[1].text\n",
    "\n",
    "            if \"watch\" in j.get(\"href\"):\n",
    "                #lien vid_url\n",
    "                vid_url = j.get(\"href\")\n",
    "\n",
    "            #update the dic\n",
    "            full_dic[date_] = {\n",
    "                \"channel\": channel_url,\n",
    "                \"vid_url\": vid_url,\n",
    "                \"channel_name\": channel_name,\n",
    "                \"vid_title\": i.find_all(name='a')[0].text\n",
    "            }\n",
    "\n",
    "    return full_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d9b72",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to convert French timestamp to useful timestamp\n",
    "def convert_french_timestamp(timestamp):\n",
    "    # Set the French locale\n",
    "    locale.setlocale(locale.LC_TIME, \"fr_FR.UTF-8\")\n",
    "    \n",
    "    # Define the timestamp format\n",
    "    format_str = \"%d %m %Y à %H:%M:%S %Z\"\n",
    "    \n",
    "    # Dictionary to map French month abbreviations to English\n",
    "    month_translation = {\n",
    "        \"janv.\": \"01\",\n",
    "        \"févr.\": \"02\",\n",
    "        \"mars\": \"03\",\n",
    "        \"avr.\": \"04\",\n",
    "        \"mai\": \"05\",\n",
    "        \"juin\": \"06\",\n",
    "        \"juil.\": \"07\",\n",
    "        \"août\": \"08\",\n",
    "        \"sept.\": \"09\",\n",
    "        \"oct.\": \"10\",\n",
    "        \"nov.\": \"11\",\n",
    "        \"déc.\": \"12\",\n",
    "    }\n",
    "    \n",
    "    # Replace the French month abbreviation with the English abbreviation\n",
    "    for french, english in month_translation.items():\n",
    "        timestamp = timestamp.replace(french, english)\n",
    "    \n",
    "    # Parse the timestamp string into a datetime object\n",
    "    dt = datetime.strptime(timestamp, format_str)\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d14800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:54:32.892183Z",
     "start_time": "2023-02-21T12:54:32.885703Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def clean_dico(dico):\n",
    "    # Mainteant on clean le dico\n",
    "    df = pd.DataFrame.from_dict(dico, orient='index')\n",
    "    df_index_reset = df.reset_index().rename(columns={\"index\": \"date\"})\n",
    "\n",
    "    df_index_reset.date = df_index_reset.date.astype(str)\n",
    "    \n",
    "    # Apply the function to the DataFrame column and convert to datetime\n",
    "    df_index_reset['date'] = df_index_reset['date'].apply(convert_french_timestamp)\n",
    "    df_index_reset['date'] = pd.to_datetime(df_index_reset['date'])\n",
    "    \n",
    "    #Let's now set our date column as index\n",
    "    df_w_dates = df_index_reset.set_index(\"date\")\n",
    "\n",
    "    #Create a column with the video ID extracted from vid_url. Allows interaction with the Youtube API v3\n",
    "    df_w_dates[\"vid_id\"] = df_w_dates.vid_url.str.extract(\n",
    "        r\"((?<=(v|V)/)|(?<=be/)|(?<=(\\?|\\&)v=)|(?<=embed/))([\\w-]+)\")[3]\n",
    "    df_cleaned = df_w_dates.copy()\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b16300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:54:32.902035Z",
     "start_time": "2023-02-21T12:54:32.894924Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fetch_details(list_of_50_ids):\n",
    "\n",
    "    #Query Google API\n",
    "    tmp_query_results = api.get_video_by_id(\n",
    "        video_id=list_of_50_ids, parts='snippet,contentDetails,statistics')\n",
    "    response_dic = tmp_query_results.to_dict()\n",
    "\n",
    "    #nombre de résultats recus via l'api\n",
    "    vid_details_dic = {}\n",
    "\n",
    "    #total_results sometimes differs from the list of 50 ids, i don't know why yet\n",
    "    for i in range(0, tmp_query_results.pageInfo.totalResults):\n",
    "\n",
    "        #get video id to join later on initial dataframe\n",
    "        vid_id_ = response_dic[\"items\"][i][\"id\"]\n",
    "\n",
    "        #duration ISO 8601 format, utiliser parse_duration de la librarie from isodate import parse_duration\n",
    "        duration_raw = response_dic[\"items\"][i][\"contentDetails\"][\"duration\"]\n",
    "        duration = isodate.parse_duration(duration_raw)\n",
    "\n",
    "        #Vid views_infos\n",
    "        nbviews = response_dic[\"items\"][i][\"statistics\"][\"viewCount\"]\n",
    "        nblikes = response_dic[\"items\"][i][\"statistics\"][\"likeCount\"]\n",
    "        nbcomments = response_dic[\"items\"][i][\"statistics\"][\"commentCount\"]\n",
    "\n",
    "        #snippet data\n",
    "        date_of_vid_publication = response_dic[\"items\"][i][\"snippet\"][\n",
    "            \"publishedAt\"]\n",
    "        vid_description = response_dic[\"items\"][i][\"snippet\"][\"description\"]\n",
    "        tags = response_dic[\"items\"][i][\"snippet\"][\"tags\"]\n",
    "\n",
    "        #appends chosen results into a dictionnary, for which the primary key is the video_id,\n",
    "        # to later be able to join on our primary df\n",
    "        vid_details_dic[vid_id_] = {\n",
    "            \"duration\": duration,\n",
    "            \"date_of_vid_publication\": date_of_vid_publication,\n",
    "            \"tags\": tags,\n",
    "            \"nbviews\": nbviews,\n",
    "            \"nblikes\": nblikes,\n",
    "            \"nbcomments\": nbcomments,\n",
    "            \"vid_description\": vid_description\n",
    "        }\n",
    "    return vid_details_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3638eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:54:32.924734Z",
     "start_time": "2023-02-21T12:54:32.919967Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_details(df_initial_clean):\n",
    "    fifty_ids_batch = []\n",
    "    bigbrain = pd.DataFrame()\n",
    "\n",
    "    # Rappel, len(df_initial_clean.vid_id) pour moi == 48000...\n",
    "    for i in range(0, len(df_initial_clean.vid_id)):\n",
    "        fifty_ids_batch.append(df_initial_clean.vid_id[i])\n",
    "\n",
    "        #tous les 50 vid_id, ie 0->49, stocker les id_s, faire appel à l'API, stocker le résultat\n",
    "        #condition i>45 parce que apparemment 1%49==0\n",
    "\n",
    "        if i % 49 == 0 and i > 45:\n",
    "\n",
    "            #Ici, on a 50 ids dans la liste, donc on peut utiliser notre fct get_vid_details dessus\n",
    "            df_tmp_results = pd.DataFrame.from_dict(\n",
    "                fetch_details(fifty_ids_batch), orient='index')\n",
    "\n",
    "            #récupérer le résultat et concatener dans notre bigbrain dataframe\n",
    "            bigbrain = pd.concat([bigbrain, df_tmp_results], axis=0)\n",
    "\n",
    "            #reset de la liste\n",
    "            fifty_ids_batch = []\n",
    "\n",
    "    return bigbrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39ea34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:54:33.410901Z",
     "start_time": "2023-02-21T12:54:33.406255Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def initialize_api(key):\n",
    "    api = Api(api_key=key)\n",
    "    return (api, api.get_authorization_url())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b41d881",
   "metadata": {},
   "source": [
    "# Extract YT history data from HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ad850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set local environment variables \n",
    "os.environ[\"YT_HISTORY_PATH\"] = \"/Users/WDescamps/Desktop/code_projects/not_pushed_yet/YouTube_Analysis/watch-history.html\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fee2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get local environment variables\n",
    "yt_hist_file_path = os.environ[\"YT_HISTORY_PATH\"]\n",
    "print(yt_hist_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b577a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:55:00.520539Z",
     "start_time": "2023-02-21T12:54:34.647768Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(yt_hist_file_path, 'r') as f:\n",
    "    contents = f.read()\n",
    "    soup = BeautifulSoup(contents, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f1520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:55:25.133340Z",
     "start_time": "2023-02-21T12:55:25.130016Z"
    }
   },
   "outputs": [],
   "source": [
    "# On fait appel a nos fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41836f1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:55:57.507332Z",
     "start_time": "2023-02-21T12:55:48.164920Z"
    }
   },
   "outputs": [],
   "source": [
    "dictionnary = parse_html_document(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0769aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dab19d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:56:28.143678Z",
     "start_time": "2023-02-21T12:56:21.633709Z"
    }
   },
   "outputs": [],
   "source": [
    "df_propre = clean_dico(dictionnary)\n",
    "df_propre.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6b42e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:56:28.143678Z",
     "start_time": "2023-02-21T12:56:21.633709Z"
    }
   },
   "outputs": [],
   "source": [
    "df_propre.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36064e27",
   "metadata": {},
   "source": [
    "## Sauvegarder en local c'est cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8371442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'YT_data.csv'\n",
    "\n",
    "df_propre.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce69aab",
   "metadata": {},
   "source": [
    "# Get  Youtube API data to enrich our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9ba1ab",
   "metadata": {},
   "source": [
    "## Récupérer la sauvegarde c'est cool aussi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9759123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer le df en mémoire, on sait jamais...\n",
    "#df_propre=pd.read_csv(full_csv_path, index_col=\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e63f4",
   "metadata": {},
   "source": [
    "## Hop on continue"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de93f8ed",
   "metadata": {},
   "source": [
    "Je vais taper sur ce endpoint de l'api youtube v3 pour enrichir mon df :\n",
    "https://developers.google.com/youtube/v3/docs/videos/list\n",
    "\n",
    "Pour ca il faut se créer une clé API youtube. Cf READ ME tout en haut de ce notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je récupère ma clé API en local \n",
    "# Cf guide sur ce lien https://towardsdatascience.com/keeping-credentials-safe-in-jupyter-notebooks-fbd215a8e311\n",
    "\n",
    "parser = ConfigParser()\n",
    "_ = parser.read('youtube_api.cfg')\n",
    "yt_api_key= parser.get('my_api', 'auth_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf50f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bdde08",
   "metadata": {},
   "outputs": [],
   "source": [
    "api, auth_url= initialize_api(yt_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5b217",
   "metadata": {},
   "source": [
    "## Get video details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b399c731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT THESE CELL TO RUN THEM - Batch calls Youtube API, 50 video ids at a time,\n",
    "# and creates a new df containing YT API data\n",
    "# This can take quite a while \n",
    "\n",
    "df_details_raw=create_details(df_propre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details_raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3bec90",
   "metadata": {},
   "source": [
    "## Sauvegarde en csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9707dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details = df_details_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8fe071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details[\"vid_id\"]=df_details.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details.date_of_vid_publication=pd.to_datetime(df_details.date_of_vid_publication)\n",
    "df_details=df_details.sort_values(\"date_of_vid_publication\", ascending=False)\n",
    "\n",
    "full_csv_path = 'YT_data_detailed.csv'\n",
    "df_details.to_csv(full_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e097574",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clean video details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9a7b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:30:06.681697Z",
     "start_time": "2023-02-21T15:30:06.495027Z"
    },
    "hidden": true
   },
   "source": [
    "### Si sauvegarde existe, Réimport du df_propre initial pour l'enrichir ensuite avec df_detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe039c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:30:06.681697Z",
     "start_time": "2023-02-21T15:30:06.495027Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_propre_path = 'YT_data.csv'\n",
    "df_propre=pd.read_csv(df_propre_path)\n",
    "#Virer la colonne ajoutée dans le read_csv\n",
    "df_propre.pop(df_propre.columns[0])\n",
    "df_propre.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573feee0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lets now join our dataframes !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04475eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:30:12.685439Z",
     "start_time": "2023-02-21T15:30:11.920089Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_details = pd.read_csv(\n",
    "    'YT_data_detailed.csv',\n",
    "    index_col=\"vid_id\")\n",
    "df_details.drop(\"Unnamed: 0\", axis=1) # Degeu, je sais, mais bon..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ceafb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:30:12.952870Z",
     "start_time": "2023-02-21T15:30:12.948831Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df_propre.shape, df_details.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f92dd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:30:13.331000Z",
     "start_time": "2023-02-21T15:30:13.215805Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Join with original dataframe\n",
    "df_joined = df_propre.merge(df_details,\n",
    "                            how=\"left\",\n",
    "                            left_on=\"vid_id\",\n",
    "                            right_index=True)\n",
    "df_joined.drop_duplicates(\"vid_id\", inplace=True)\n",
    "df_joined.date = pd.to_datetime(df_joined.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b5675a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:47:19.412486Z",
     "start_time": "2023-02-21T15:47:19.408802Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df_joined.columns, \"\\n\", df_joined.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c0b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:47:22.387366Z",
     "start_time": "2023-02-21T15:47:22.374436Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_joined.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86683385",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd80c62",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "full_csv_path = 'YT_data_joinde.csv'\n",
    "df_joined.to_csv(full_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40d18e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21592989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:30:16.113163Z",
     "start_time": "2023-02-21T15:30:16.103619Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# How many rows without tag? Probably before the creation of tags by the platform\n",
    "df_joined.tags.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450e9f0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Split each year into a dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c634cff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:30:21.900691Z",
     "start_time": "2023-02-21T15:30:21.855729Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creates Yearly Dataframes and puts them in a dictionnary with \"{year}\" as a key\n",
    "list_of_years = df_joined.date.dt.year.unique()\n",
    "dic_years = {}\n",
    "\n",
    "for year_ in list_of_years:\n",
    "    dic_years[str(year_)] = df_joined[df_joined.date.dt.year ==\n",
    "                                      year_].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae91cc8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Now let's have fun analysing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ccd7fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:30:24.543064Z",
     "start_time": "2023-02-21T15:30:24.530867Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#How many unique videos have i watched per channel? Top 10 of all time\n",
    "df_joined.channel_name.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ddcb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:40:32.389070Z",
     "start_time": "2023-02-21T15:40:32.383888Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_most_watched_tags_in_year(year):\n",
    "    \n",
    "    import re\n",
    "    #Créer une nouvelle colonne avec un dictionnaire pour chaque row avec la cellule ci-dessous\n",
    "    #Si possible, ajouter 1 où une clé existe deja, sinon crée autre clé\n",
    "    result = {}\n",
    "    for tag in dic_years[year][\"tags\"]:\n",
    "        list_of_tags= list(re.findall(r\"'\\s*([^']+?)\\s*'\", str(tag)))\n",
    "        for item in list_of_tags:\n",
    "\n",
    "            if f\"{item}\" not in result:\n",
    "                result[str(item)]=1\n",
    "            else:\n",
    "                result[str(item)]+=1\n",
    "                \n",
    "    tag_results_df=pd.DataFrame.from_dict(result, orient=\"index\", columns=[\"count\"]).reset_index()\n",
    "    sorted_results=tag_results_df.sort_values(\"count\", ascending=False)\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c0aaca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:44:08.280915Z",
     "start_time": "2023-02-21T15:44:08.099216Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Maintenant on peut jouer a voir chaque tag par année. On pourrait voir comment ils progressent chaque année\n",
    "get_most_watched_tags_in_year(\"2020\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e78ec",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Yearly watch history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9eeea1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:52:08.898072Z",
     "start_time": "2023-02-21T15:52:08.885836Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dic_years[\"2022\"].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e51b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:54:28.632238Z",
     "start_time": "2023-02-21T15:54:28.629462Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Plot yearly consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78403046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:56:32.214104Z",
     "start_time": "2023-02-21T15:56:32.149507Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "annee=\"2017\"\n",
    "\n",
    "nb_vids_per_week = dic_years[annee].groupby(\n",
    "    dic_years[annee].date.dt.to_period(\"W\"))[[\"vid_id\"]].agg('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db0120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T15:59:22.178299Z",
     "start_time": "2023-02-21T15:59:22.002079Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nb_vids_per_week.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978e8fa4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### How did my time spent on the platform evolve YoY?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da259d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T08:03:15.875316Z",
     "start_time": "2023-02-21T08:03:15.872408Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Plot YoY consuption on the same graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a9677",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "494a7123",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Which tags are the most frequent? How do they evolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28cc00",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### What about descriptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c84561",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f19556cc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### What about time spent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93dad47",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9796bdb0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Do i watch new or old videos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f278cb8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Add Captions (In progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7ad00",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Try to get caption/subtitles a single video NOT WORKING\n",
    "\n",
    "Caption = api.get_captions_by_video(\n",
    "    video_id='Z_QnyfEokg8',\n",
    "    caption_id='AUieDaaAJvMo8nUKiqUuP6X0QbXKb9xcpjTY4mT5-Ny41JpLys8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b2a0ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7467694",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/14061195/how-to-get-transcript-in-youtube-api-v3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
